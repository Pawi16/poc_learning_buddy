[
  {
    "title": "Computer Networks and the Internet",
    "content": "Today’s Internet is arguably the largest engineered system ever created by mankind,\nwith hundreds of millions of connected computers, communication links, and\nswitches; with billions of users who connect via laptops, tablets, and smartphones;\nand with an array of new Internet-connected devices such as sensors, Web cams,\ngame consoles, picture frames, and even washing machines. Given that the Internet\nis so large and has so many diverse components and uses, is there any hope of\nunderstanding how it works? Are there guiding principles and structure that can pro-\nvide a foundation for understanding such an amazingly large and complex system?\nAnd if so, is it possible that it actually could be both interesting and fun to learn\nabout computer networks? Fortunately, the answers to all of these questions is a\nresounding YES! Indeed, it’s our aim in this book to provide you with a modern\nintroduction to the dynamic field of computer networking, giving you the principles\nand practical insights you’ll need to understand not only today’s networks, but\ntomorrow’s as well.\nThis first chapter presents a broad overview of computer networking and the\nInternet. Our goal here is to paint a broad picture and set the context for the rest of\nthis book, to see the forest through the trees. We’ll cover a lot of ground in this intro-\nductory chapter and discuss a lot of the pieces of a computer network, without los-\ning sight of the big picture.\nWe’ll structure our overview of computer networks in this chapter as follows.\nAfter introducing some basic terminology and concepts, we’ll first examine the\nbasic hardware and software components that make up a network. We’ll begin at\nthe network’s edge and look at the end systems and network applications running\nin the network. We’ll then explore the core of a computer network, examining the\nlinks and the switches that transport data, as well as the access networks and phys-\nical media that connect end systems to the network core. We’ll learn that the Inter-\nnet is a network of networks, and we’ll learn how these networks connect with\neach other.\nAfter having completed this overview of the edge and core of a computer net-\nwork, we’ll take the broader and more abstract view in the second half of this chap-\nter. We’ll examine delay, loss, and throughput of data in a computer network and\nprovide simple quantitative models for end-to-end throughput and delay: models\nthat take into account transmission, propagation, and queuing delays. We’ll then\nintroduce some of the key architectural principles in computer networking, namely,\nprotocol layering and service models. We’ll also learn that computer networks are\nvulnerable to many different types of attacks; we’ll survey some of these attacks and\nconsider how computer networks can be made more secure. Finally, we’ll close this\nchapter with a brief history of computer networking.\n"
  },
  {
    "title": "1.1 What Is the Internet?",
    "content": "In this book, we’ll use the public Internet, a specific computer network, as our prin-\ncipal vehicle for discussing computer networks and their protocols. But what is the\nInternet? There are a couple of ways to answer this question. First, we can describe\nthe nuts and bolts of the Internet, that is, the basic hardware and software components\nthat make up the Internet. Second, we can describe the Internet in terms of a net-\nworking infrastructure that provides services to distributed applications. Let’s begin\nwith the nuts-and-bolts description, using Figure 1.1to illustrate our discussion.\n"
  },
  {
    "title": "1.1.1 A Nuts-and-Bolts Description",
    "content": "The Internet is a computer network that interconnects hundreds of millions of com-\nputing devices throughout the world. Not too long ago, these computing devices were\nprimarily traditional desktop PCs, Linux workstations, and so-called servers that store\nand transmit information such as Web pages and e-mail messages. Increasingly,\nhowever, nontraditional Internet end systems such as laptops, smartphones, tablets,\nTVs, gaming consoles, Web cams, automobiles, environmental sensing devices,\npicture frames, and home electrical and security systems are being connected to the\nInternet. Indeed, the term computer network is beginning to sound a bit dated, given\nKey:\nHost\nServer Mobile Router Link-Layer\nModem Base\nSmartphone Cell phone\nNational or\nGlobal ISP\nMobile Network\nLocal or\nRegional ISP\nEnterprise Network\nHome Network\nnearly 850 million end systems attached to the Internet [ISC 2012], not counting\nsmartphones, laptops, and other devices that are only intermittently connected to the\nInternet.Overall, more there are an estimated 2 billion Internet users [ITU 2011].\nEnd systems are connected together by a network of communication links and\npacket switches . We’ll see in Section 1.2 that there are many types of communica-\ntion links, which are made up of different types of physical media, including coaxial\ncable, copper wire, optical fiber, and radio spectrum. Different links can transmit\ndata at different rates, with the transmission rate of a link measured in bits/second.\nWhen one end system has data to send to another end system, the sending end sys-\ntem segments the data and adds header bytes to each segment. The resulting pack-\nages of information, known as packets in the jargon of computer networks, are then\nsent through the network to the destination end system, where they are reassembled\ninto the original data.\nApacket switch takes a packet arriving on one of its incoming communication\nlinks and forwards that packet on one of its outgoing communication links. Packet\nswitches come in many shapes and flavors, but the two most prominent types in\ntoday’s Internet are routers and link-layerswitches . Both types of switches for-\nward packets toward their ultimate destinations. Link-layer switches are typically\nused in access networks, while routers are typically used in the network core. The\nsequence of communication links and packet switches traversed by a packet from\nthe sending end system to the receiving end system is known as a route or path\nthrough the network. The exact amount of traffic being carried in the Internet is\ndifficult to estimate but Cisco [Cisco VNI 2011] estimates global Internet traffic will\nbe nearly 40 exabytes per month in 2012.\nPacket-switched networks (which transport packets) are in many ways simi-\nlar to transportation networks of highways, roads, and intersections (which trans-\nport vehicles). Consider, for example, a factory that needs to move a large\namount of cargo to some destination warehouse located thousands of kilometers\naway. At the factory, the cargo is segmented and loaded into a fleet of trucks.\nEach of the trucks then independently travels through the network of highways,\nroads, and intersections to the destination warehouse. At the destination ware-\nhouse, the cargo is unloaded and grouped with the rest of the cargo arriving from\nthe same shipment. Thus, in many ways, packets are analogous to trucks, com-\nmunication links are analogous to highways and roads, packet switches are anal-\nogous to intersections, and end systems are analogous to buildings. Just as a truck\ntakes a path through the transportation network, a packet takes a path through a\ncomputer network.\nEnd systems access the Internet through Internet Service Providers (ISPs) ,\nincluding residential ISPs such as local cable or telephone companies; corporate\nISPs; university ISPs; and ISPs that provide WiFi access in airports, hotels, coffee\nshops, and other public places. Each ISPis in itself a network of packet switches\nand communication links. ISPs provide a variety of types of network access to the\nhigh-speed local area network access, wireless access, and 56 kbps dial-up modem\naccess. ISPs also provide Internet access to content providers, connecting Web\nsites directly to the Internet. The Internet is all about connecting end systems to\neach other, so the ISPs that provide access to end systems must also be intercon-\nnected. These lower-tier ISPs are interconnected through national and interna-\ntional upper-tier ISPs such as Level 3 Communications, AT&T, Sprint, and NTT.\nAn upper-tier ISPconsists of high-speed routers interconnected with high-speed\nfiber-optic links. Each ISPnetwork, whether upper-tier or lower-tier, is managed\nindependently, runs the IPprotocol (see below), and conforms to certain naming\nand address conventions. We’ll examine ISPs and their interconnection more\nclosely in Section 1.3.\nEnd systems, packet switches, and other pieces of the Internet run protocols\nthat control the sending and receiving of information within the Internet. The\nTransmission Control Protocol (TCP) and the Internet Protocol (IP) are two of\nthe most important protocols in the Internet. The IPprotocol specifies the format of\nthe packets that are sent and received among routers and end systems. The Internet’s\nprincipal protocols are collectively known as TCP/IP . We’ll begin looking into pro-\ntocols in this introductory chapter. But that’s just a start—much of this book is con-\ncerned with computer network protocols!\nGiven the importance of protocols to the Internet, it’s important that everyone\nagree on what each and every protocol does, so that people can create systems and\nproducts that interoperate. This is where standards come into play. Internet stan-\ndards are developed by the Internet Engineering Task Force (IETF)[IETF 2012].\nThe IETF standards documents are called requests forcomments (RFCs) . RFCs\nstarted out as general requests for comments (hence the name) to resolve network\nand protocol design problems that faced the precursor to the Internet [Allman 2011].\nRFCs tend to be quite technical and detailed. They define protocols such as TCP, IP,\nHTTP(for the Web), and SMTP(for e-mail). There are currently more than 6,000\nRFCs. Other bodies also specify standards for network components, most notably\nfor network links. The IEEE 802 LAN/MAN Standards Committee [IEEE 802\n2012], for example, specifies the Ethernet and wireless WiFi standards.\n"
  },
  {
    "title": "1.1.2 A Services Description",
    "content": "Our discussion above has identified many of the pieces that make up the Internet.\nBut we can also describe the Internet from an entirely different angle—namely, as\nan infrastructure that provides services to applications . These applications\ninclude electronic mail, Web surfing, social networks, instant messaging, Voice-\nover-IP(VoIP), video streaming, distributed games, peer-to-peer (P2P) file shar-\ning, television over the Internet, remote login, and much, much more. The\napplications are said to be distributed applications ,since they involve multiple\nrun on end systems—they do not run in the packet switches in the network core.\nAlthough packet switches facilitate the exchange of data among end systems, they\nare not concerned with the application that is the source or sink of data.\nLet’s explore a little more what we mean by an infrastructure that provides\nservices to applications. To this end, suppose you have an exciting new idea for a\ndistributed Internet application, one that may greatly benefit humanity or one that\nmay simply make you rich and famous. How might you go about transforming\nthis idea into an actual Internet application? Because applications run on end sys-\ntems, you are going to need to write programs that run on the end systems. You\nmight, for example, write your programs in Java, C, or Python. Now, because you\nare developing a distributed Internet application, the programs running on the\ndifferent end systems will need to send data to each other. And here we get to a\ncentral issue—one that leads to the alternative way of describing the Internet as a\nplatform for applications. How does one program running on one end system\ninstruct the Internet to deliver data to another program running on another end\nsystem?\nEnd systems attached to the Internet provide an Application Programming\nInterface (API) that specifies how a program running on one end system asks\nthe Internet infrastructure to deliver data to a specific destination program run-\nning on another end system. This Internet API is a set of rules that the sending\nprogram must follow so that the Internet can deliver the data to the destination\nprogram. We’ll discuss the Internet API in detail in Chapter 2. For now, let’s\ndraw upon a simple analogy, one that we will frequently use in this book. Sup-\npose Alice wants to send a letter to Bob using the postal service. Alice, of course,\ncan’t just write the letter (the data) and drop the letter out her window. Instead,\nthe postal service requires that Alice put the letter in an envelope; write Bob’s\nfull name, address, and zip code in the center of the envelope; seal the envelope;\nput a stamp in the upper-right-hand corner of the envelope; and finally, drop the\nenvelope into an official postal service mailbox. Thus, the postal service has its\nown “postal service API,” or set of rules, that Alice must follow to have the\npostal service deliver her letter to Bob. In a similar manner, the Internet has an\nAPI that the program sending data must follow to have the Internet deliver the\ndata to the program that will receive the data.\nThe postal service, of course, provides more than one service to its customers.\nIt provides express delivery, reception confirmation, ordinary use, and many more\nservices. In a similar manner, the Internet provides multiple services to its applica-\ntions. When you develop an Internet application, you too must choose one of the\nInternet’s services for your application. We’ll describe the Internet’s services in\nChapter 2.\nWe have just given two descriptions of the Internet; one in terms of its hardware\nand software components, the other in terms of an infrastructure for providing\nservices to distributed applications. But perhaps you are still confused as to what the\nInternet is. What are packet switching and TCP/IP? What are routers? What kinds of\ncommunication links are present in the Internet? What is a distributed application?\nHow can a toaster or a weather sensor be attached to the Internet? If you feel a bit\noverwhelmed by all of this now, don’t worry—the purpose of this book is to intro-\nduce you to both the nuts and bolts of the Internet and the principles that govern how\nand why it works. We’ll explain these important terms and questions in the follow-\ning sections and chapters.\n"
  },
  {
    "title": "1.1.3 What Is a Protocol?",
    "content": "Now that we’ve got a bit of a feel for what the Internet is, let’s consider another\nimportant buzzword in computer networking: protocol . What is a protocol? What\ndoes a protocol do ?\nA Human Analogy\nIt is probably easiest to understand the notion of a computer network protocol by\nfirst considering some human analogies, since we humans execute protocols all of\nthe time. Consider what you do when you want to ask someone for the time of day.\nAtypical exchange is shown in Figure 1.2. Human protocol (or good manners, at\nleast) dictates that one first offer a greeting (the first “Hi” in Figure 1.2) to initiate\ncommunication with someone else. The typical response to a “Hi” is a returned\n“Hi” message. Implicitly, one then takes a cordial “Hi” response as an indication\nthat one can proceed and ask for the time of day. Adifferent response to the initial\n“Hi” (such as “Don’t bother me!” or “I don’t speak English,” or some unprintable\nreply) might indicate an unwillingness or inability to communicate. In this case,\nthe human protocol would be not to ask for the time of day. Sometimes one gets no\nresponse at all to a question, in which case one typically gives up asking that per-\nson for the time. Note that in our human protocol, there are specific messages we\nsend, and specific actions we take in response to the received reply messages or\nother events (such as no reply within some given amount of time). Clearly, trans-\nmitted and received messages, and actions taken when these messages are sent or\nreceived or other events occur, play a central role in a human protocol. If people\nrun different protocols (for example, if one person has manners but the other does\nnot, or if one understands the concept of time and the other does not) the protocols\ndo not interoperate and no useful work can be accomplished. The same is true in\nnetworking—it takes two (or more) communicating entities running the same pro-\ntocol in order to accomplish a task.\nLet’s consider a second human analogy. Suppose you’re in a college class (a\ncomputer networking class, for example!). The teacher is droning on about proto-\ncols and you’re confused. The teacher stops to ask, “Are there any questions?” (a\nmessage that is transmitted to, and received by, all students who are not sleeping).\nYou raise your hand (transmitting an implicit message to the teacher). Your teacher\nacknowledges you with a smile, saying “Yes . . .” (a transmitted message encourag-\ning you to ask your question—teachers love to be asked questions), and you then ask\nyour question (that is, transmit your message to your teacher). Your teacher hears\nyour question (receives your question message) and answers (transmits a reply to\nyou). Once again, we see that the transmission and receipt of messages, and a set of\nconventional actions taken when these messages are sent and received, are at the\nheart of this question-and-answer protocol.\nNetwork Protocols\nAnetwork protocol is similar to a human protocol, except that the entities exchang-\ning messages and taking actions are hardware or software components of some\nG E T h t t p : / / w w w . a w l . c o m / k u r o s e - r o s s\nT C P c o n n e c t i o n r e q u e s t\nTime Time\nT C P c o n n e c t i o n r e p l y\n< f i l e >\nH i\nG o t t h e t i m e ?\nTime Time\nH i\n2 : 0 0\ndevice). All activity in the Internet that involves two or more communicating remote\nentities is governed by a protocol. For example, hardware-implemented protocols in\ntwo physically connected computers control the flow of bits on the “wire” between\nthe two network interface cards; congestion-control protocols in end systems con-\ntrol the rate at which packets are transmitted between sender and receiver; protocols\nin routers determine a packet’s path from source to destination. Protocols are run-\nning everywhere in the Internet, and consequently much of this book is about com-\nputer network protocols.\nAs an example of a computer network protocol with which you are probably\nfamiliar, consider what happens when you make a request to a Web server, that is,\nwhen you type the URLof a Web page into your Web browser. The scenario is illus-\ntrated in the right half of Figure 1.2. First, your computer will send a connection\nrequest message to the Web server and wait for a reply. The Web server will eventu-\nally receive your connection request message and return a connection reply mes-\nsage. Knowing that it is now OK to request the Web document, your computer then\nsends the name of the Web page it wants to fetch from that Web server in a GET\nmessage. Finally, the Web server returns the Web page (file) to your computer.\nGiven the human and networking examples above, the exchange of messages\nand the actions taken when these messages are sent and received are the key defin-\ning elements of a protocol:\nAprotocoldefines the format and the order of messages exchanged between\ntwo or more communicating entities, as well as the actions taken on the trans-\nmission and/or receipt of a message or other event.\nThe Internet, and computer networks in general, make extensive use of proto-\ncols. Different protocols are used to accomplish different communication tasks. As\nyou read through this book, you will learn that some protocols are simple and\nstraightforward, while others are complex and intellectually deep. Mastering the\nfield of computer networking is equivalent to understanding the what, why, and how\nof networking protocols.\n"
  },
  {
    "title": "1.2 The Network Edge",
    "content": "In the previous section we presented a high-level overview of the Internet and net-\nworking protocols. We are now going to delve a bit more deeply into the compo-\nnents of a computer network (and the Internet, in particular). We begin in this\nsection at the edge of a network and look at the components with which we are most\nfamiliar—namely, the computers, smartphones and other devices that we use on a\ndaily basis. In the next section we’ll move from the network edge to the network\nRecall from the previous section that in computer networking jargon, the com-\nputers and other devices connected to the Internet are often referred to as end sys-\ntems. They are referred to as end systems because they sit at the edge of the Internet,\nas shown in Figure 1.3. The Internet’s end systems include desktop computers (e.g.,\ndesktop PCs, Macs, and Linux boxes), servers (e.g., Web and e-mail servers), and\nmobile computers (e.g., laptops, smartphones, and tablets). Furthermore, an increas-\ning number of non-traditional devices are being attached to the Internet as end sys-\ntems (see sidebar).\nEnd systems are also referred to as hosts because they host (that is, run) appli-\ncation programs such as a Web browser program, a Web server program, an e-mail\nclient program, or an e-mail server program. Throughout this book we will use the\nterms hosts and end systems interchangeably; that is, host = end system . Hosts are\nsometimes further divided into two categories: clients and servers . Informally,\nclients tend to be desktop and mobile PCs, smartphones, and so on, whereas servers\ntend to be more powerful machines that store and distribute Web pages, stream\nA DIZZYING ARRAY OF INTERNET END SYSTEMS\nNot too long ago, the end-system devices connected to the Internet were primarily\ntraditional computers such as desktop machines and powerful servers. Beginning in\nthe late 1990s and continuing today, a wide range of interesting devices are being\nconnected to the Internet, leveraging their ability to send and receive digital data.\nGiven the Internet’s ubiquity, its well-defined (standardized) protocols, and the\navailability of Internet-ready commodity hardware, it’s natural to use Internet tech-\nnology to network these devices together and to Internet-connected servers.\nMany of these devices are based in the home—video game consoles (e.g.,\nMicrosoft’s Xbox), Internet-ready televisions, digital picture frames that download\nand display digital pictures, washing machines, refrigerators, and even a toaster\nthat downloads meteorological information and burns an image of the day’s fore-\ncast (e.g., mixed clouds and sun) on your morning toast [BBC 2001]. IP-enabled\nphones with GPS capabilities put location-dependent services (maps, information\nabout nearby services or people) at your fingertips. Networked sensors embedded\ninto the physical environment allow monitoring of buildings, bridges, seismic activi-\nty, wildlife habitats, river estuaries, and the weather. Biomedical devices can be\nembedded and networked in a body-area network. With so many diverse devices\nbeing networked together, the Internet is indeed becoming an “Internet of things”\n[ITU 2005b].\n"
  },
  {
    "title": "CASE HISTORY",
    "content": "search results, e-mail, Web pages, and videos reside in large data centers . For\nexample, Google has 30–50 data centers, with many having more than one hundred\nMobile Network\nNational or\nGlobal ISP\nLocal or\nRegional ISP\nEnterprise Network\nHome Network\nNational or\nGlobal ISP\nMobile Network\nLocal or\nRegional ISP\nEnterprise Network\nHome Network\n"
  },
  {
    "title": "1.2.1 Access Networks",
    "content": "Having considered the applications and end systems at the “edge of the network,”\nlet’s next consider the access network—the network that physically connects an end\nsystem to the first router (also known as the “edge router”) on a path from the end\nsystem to any other distant end system. Figure 1.4 shows several types of access\nnetworks with thick, shaded lines, and the settings (home, enterprise, and wide-area\nmobile wireless) in which they are used.\nHome Access: DSL, Cable, FTTH, Dial-Up, and Satellite\nIn developed countries today, more than 65 percent of the households have Internet\naccess, with Korea, Netherlands, Finland, and Sweden leading the way with more than\n80 percent of households having Internet access, almost all via a high-speed broadband\nconnection [ITU 2011]. Finland and Spain have recently declared high-speed Internet\naccess to be a “legal right.” Given this intense interest in home access, let’s begin our\noverview of access networks by considering how homes connect to the Internet.\nToday, the two most prevalent types of broadband residential access are digital\nsubscriberline (DSL) and cable. Aresidence typically obtains DSLInternet access\nfrom the same local telephone company (telco) that provides its wired local phone\naccess. Thus, when DSL is used, a customer’s telco is also its ISP. As shown in\npair copper wire, which we’ll discuss in Section 1.2.2) to exchange data with a digi-\ntal subscriber line access multiplexer (DSLAM) located in the telco’s local central\noffice (CO). The home’s DSLmodem takes digital data and translates it to high-\nfrequency tones for transmission over telephone wires to the CO; the analog signals\nfrom many such houses are translated back into digital format at the DSLAM.\nThe residential telephone line carries both data and traditional telephone sig-\nnals simultaneously, which are encoded at different frequencies:\n• Ahigh-speed downstream channel, in the 50 kHz to 1 MHz band\n• Amedium-speed upstream channel, in the 4 kHz to 50 kHz band\n• An ordinary two-way telephone channel, in the 0 to 4 kHz band\nThis approach makes the single DSL link appear as if there were three separate\nlinks, so that a telephone call and an Internet connection can share the DSLlink at\nthe same time. (We’ll describe this technique of frequency-division multiplexing in\nHome\nphone\nDSL\nmodem\nInternet\nTelephone\nnetwork\nSplitter\nExisting phone line:\n0-4KHz phone; 4-50KHz\nupstream data; 50KHz–\n1MHz downstream data\nCentral\noffice\nDSLAM\nSection 1.3.1). On the customer side, a splitter separates the data and telephone sig-\nnals arriving to the home and forwards the data signal to the DSLmodem. On the\ntelco side, in the CO, the DSLAM separates the data and phone signals and sends\nthe data into the Internet. Hundreds or even thousands of households connect to a\nsingle DSLAM [Dischinger 2007].\nThe DSL standards define transmission rates of 12 Mbps downstream and\n1.8 Mbps upstream [ITU 1999], and 24 Mbps downstream and 2.5 Mbps upstream\n[ITU 2003]. Because the downstream and upstream rates are different, the access is\nsaid to be asymmetric. The actual downstream and upstream transmission rates\nachieved may be less than the rates noted above, as the DSLprovider may purpose-\nfully limit a residential rate when tiered service (different rates, available at differ-\nent prices) are offered, or because the maximum rate can be limited by the distance\nbetween the home and the CO, the gauge of the twisted-pair line and the degree of\nelectrical interference. Engineers have expressly designed DSLfor short distances\nbetween the home and the CO; generally, if the residence is not located within 5 to 10\nmiles of the CO, the residence must resort to an alternative form of Internet access.\nWhile DSLmakes use of the telco’s existing local telephone infrastructure,\ncable Internet access makes use of the cable television company’s existing cable\ntelevision infrastructure. Aresidence obtains cable Internet access from the same\ncompany that provides its cable television. As illustrated in Figure 1.6, fiber optics\nconnect the cable head end to neighborhood-level junctions, from which tradi-\ntional coaxial cable is then used to reach individual houses and apartments. Each\nneighborhood junction typically supports 500 to 5,000 homes. Because both fiber\nand coaxial cable are employed in this system, it is often referred to as hybrid\nfiber coax (HFC).\nFiber\ncable\nCoaxial cable\nHundreds\nof homes\nCable head end\nHundreds\nof homes\nFiber\nnode\nFiber\nnode\nInternet\nCMTS\nCable internet access requires special modems, called cable modems. As with a\nDSLmodem, the cable modem is typically an external device and connects to the\nhome PC through an Ethernet port. (We will discuss Ethernet in great detail in\nChapter 5.) At the cable head end, the cable modem termination system (CMTS)\nserves a similar function as the DSLnetwork’s DSLAM—turning the analog signal\nsent from the cable modems in many downstream homes back into digital format.\nCable modems divide the HFC network into two channels, a downstream and an\nupstream channel. As with DSL, access is typically asymmetric, with the down-\nstream channel typically allocated a higher transmission rate than the upstream\nchannel. The DOCSIS 2.0 standard defines downstream rates up to 42.8 Mbps and\nupstream rates of up to 30.7 Mbps. As in the case of DSLnetworks, the maximum\nachievable rate may not be realized due to lower contracted data rates or media\nimpairments.\nOne important characteristic of cable Internet access is that it is a shared\nbroadcast medium. In particular, every packet sent by the head end travels down-\nstream on every link to every home and every packet sent by a home travels on the\nupstream channel to the head end. For this reason, if several users are simultane-\nously downloading a video file on the downstream channel, the actual rate at which\neach user receives its video file will be significantly lower than the aggregate cable\ndownstream rate. On the other hand, if there are only a few active users and they\nare all Web surfing, then each of the users may actually receive Web pages at the\nfull cable downstream rate, because the users will rarely request a Web page at\nexactly the same time. Because the upstream channel is also shared, a distributed\nmultiple access protocol is needed to coordinate transmissions and avoid collisions.\n(We’ll discuss this collision issue in some detail in Chapter 5.)\nAlthough DSLand cable networks currently represent more than 90 percent of\nresidential broadband access in the United States, an up-and-coming technology that\npromises even higher speeds is the deployment of fiber to the home (FTTH)\n[FTTH Council 2011a]. As the name suggests, the FTTH concept is simple—\nprovide an optical fiber path from the CO directly to the home. In the United States,\nVerizon has been particularly aggressive with FTTH with its FIOS service [Verizon\nFIOS 2012].\nThere are several competing technologies for optical distribution from the\nCO to the homes. The simplest optical distribution network is called direct fiber,\nwith one fiber leaving the CO for each home. More commonly, each fiber leav-\ning the central office is actually shared by many homes; it is not until the fiber\ngets relatively close to the homes that it is split into individual customer-specific\nfibers. There are two competing optical-distribution network architectures that\nperform this splitting: active optical networks (AONs) and passive optical net-\nworks (PONs). AON is essentially switched Ethernet, which is discussed in\nChapter 5.\nHere, we briefly discuss PON, which is used in Verizon’s FIOS service.\nan optical network terminator (ONT), which is connected by dedicated optical\nfiber to a neighborhood splitter. The splitter combines a number of homes (typically\nless than 100) onto a single, shared optical fiber, which connects to an optical line\nterminator (OLT) in the telco’s CO. The OLT, providing conversion between optical\nand electrical signals, connects to the Internet via a telco router. In the home, users\nconnect a home router (typically a wireless router) to the ONTand access the Inter-\nnet via this home router. In the PON architecture, all packets sent from OLTto the\nsplitter are replicated at the splitter (similar to a cable head end).\nFTTH can potentially provide Internet access rates in the gigabits per second\nrange. However, most FTTH ISPs provide different rate offerings, with the higher\nrates naturally costing more money. The average downstream speed of US FTTH\ncustomers was approximately 20 Mbps in 2011 (compared with 13 Mbps for cable\naccess networks and less than 5 Mbps for DSL) [FTTH Council 2011b].\nTwo other access network technologies are also used to provide Internet access\nto the home. In locations where DSL, cable, and FTTH are not available (e.g., in\nsome rural settings), a satellite link can be used to connect a residence to the Inter-\nnet at speeds of more than 1 Mbps; StarBand and HughesNet are two such satellite\naccess providers. Dial-up access over traditional phone lines is based on the same\nmodel as DSL—a home modem connects over a phone line to a modem in the ISP.\nCompared with DSLand other broadband access networks, dial-up access is excru-\nciatingly slow at 56 kbps.\nAccess in the Enterprise (and the Home): Ethernet and WiFi\nOn corporate and university campuses, and increasingly in home settings, a local area\nnetwork (LAN) is used to connect an end system to the edge router. Although there\nare many types of LAN technologies, Ethernet is by far the most prevalent access\nInternet\nCentral office\nOptical\nsplitter\nONT\nONT\nONT\nOLT\nOptical\nfibers\ntechnology discussed in detail in Chapter 5. The Ethernet switch, or a network of\nsuch interconnected switches, is then in turn connected into the larger Internet. With\nEthernet access, users typically have 100 Mbps access to the Ethernet switch,\nwhereas servers may have 1 Gbps or even 10 Gbps access.\nIncreasingly, however, people are accessing the Internet wirelessly from lap-\ntops, smartphones, tablets, and other devices (see earlier sidebar on “ADizzying\nArray of Devices”). In a wireless LAN setting, wireless users transmit/receive pack-\nets to/from an access point that is connected into the enterprise’s network (most\nlikely including wired Ethernet), which in turn is connected to the wired Internet. A\nwireless LAN user must typically be within a few tens of meters of the access point.\nWireless LAN access based on IEEE 802.11 technology, more colloquially known\nas WiFi, is now just about everywhere—universities, business offices, cafes, air-\nports, homes, and even in airplanes. In many cities, one can stand on a street corner\nand be within range of ten or twenty base stations (for a browseable global map of\n802.11 base stations that have been discovered and logged on a Web site by people\nwho take great enjoyment in doing such things, see [wigle.net 2012]). As discussed\nin detail in Chapter 6, 802.11 today provides a shared transmission rate of up to\n54 Mbps.\nEven though Ethernet and WiFi access networks were initially deployed in enter-\nprise (corporate, university) settings, they have recently become relatively common\ncomponents of home networks. Many homes combine broadband residential access\n(that is, cable modems or DSL) with these inexpensive wireless LAN technologies to\ncreate powerful home networks [Edwards 2011]. Figure 1.9shows a typical home\nnetwork. This home network consists of a roaming laptop as well as a wired PC; a\nbase station (the wireless access point), which communicates with the wireless PC; a\ncable modem, providing broadband access to the Internet; and a router, which inter-\nconnects the base station and the stationary PC with the cable modem. This network\nEthernet\nswitch\nInstitutional\nrouter\n100 Mbps\n100 Mbps\n100 Mbps\nServer\nTo Institution’s\nISP\nWide-Area Wireless Access: 3G and LTE\nIncreasingly, devices such as iPhones, BlackBerrys, and Android devices are being\nused to send email, surf the Web, Tweet, and download music while on the run.\nThese devices employ the same wireless infrastructure used for cellular telephony\nto send/receive packets through a base station that is operated by the cellular net-\nwork provider. Unlike WiFi, a user need only be within a few tens of kilometers (as\nopposed to a few tens of meters) of the base station.\nTelecommunications companies have made enormous investments in so-called\nthird-generation (3G) wireless, which provides packet-switched wide-area wireless\nInternet access at speeds in excess of 1 Mbps. But even higher-speed wide-area\naccess technologies—a fourth-generation (4G) of wide-area wireless networks—are\nalready being deployed. LTE ( for “Long-Term Evolution”—a candidate for Bad\nAcronym of the Year Award) has its roots in 3G technology, and can potentially\nachieve rates in excess of 10 Mbps. LTE downstream rates of many tens of Mbps\nhave been reported in commercial deployments. We’ll cover the basic principles of\nwireless networks and mobility, as well as WiFi, 3G, and LTE technologies (and\nmore!) in Chapter 6.\n"
  },
  {
    "title": "1.2.2 Physical Media",
    "content": "In the previous subsection, we gave an overview of some of the most important\nnetwork access technologies in the Internet. As we described these technologies,\nwe also indicated the physical media used. For example, we said that HFC uses a\ncombination of fiber cable and coaxial cable. We said that DSLand Ethernet use\ncopper wire. And we said that mobile access networks use the radio spectrum.\nCable\nhead end\nHouse\nInternet\nIn this subsection we provide a brief overview of these and other transmission\nmedia that are commonly used in the Internet.\nIn order to define what is meant by a physical medium, let us reflect on the\nbrief life of a bit. Consider a bit traveling from one end system, through a series of\nlinks and routers, to another end system. This poor bit gets kicked around and\ntransmitted many, many times! The source end system first transmits the bit, and\nshortly thereafter the first router in the series receives the bit; the first router then\ntransmits the bit, and shortly thereafter the second router receives the bit; and so\non. Thus our bit, when traveling from source to destination, passes through a series\nof transmitter-receiver pairs. For each transmitter-receiver pair, the bit is sent by\npropagating electromagnetic waves or optical pulses across a physical medium .\nThe physical medium can take many shapes and forms and does not have to be of\nthe same type for each transmitter-receiver pair along the path. Examples of physi-\ncal media include twisted-pair copper wire, coaxial cable, multimode fiber-optic\ncable, terrestrial radio spectrum, and satellite radio spectrum. Physical media fall\ninto two categories: guided media and unguided media . With guided media, the\nwaves are guided along a solid medium, such as a fiber-optic cable, a twisted-pair\ncopper wire, or a coaxial cable. With unguided media, the waves propagate in the\natmosphere and in outer space, such as in a wireless LAN or a digital satellite\nchannel.\nBut before we get into the characteristics of the various media types, let us say\na few words about their costs. The actual cost of the physical link (copper wire,\nfiber-optic cable, and so on) is often relatively minor compared with other network-\ning costs. In particular, the labor cost associated with the installation of the physical\nlink can be orders of magnitude higher than the cost of the material. For this reason,\nmany builders install twisted pair, optical fiber, and coaxial cable in every room in a\nbuilding. Even if only one medium is initially used, there is a good chance that\nanother medium could be used in the near future, and so money is saved by not hav-\ning to lay additional wires in the future.\nTwisted-Pair Copper Wire\nThe least expensive and most commonly used guided transmission medium is\ntwisted-pair copper wire. For over a hundred years it has been used by telephone\nnetworks. In fact, more than 99 percent of the wired connections from the tele-\nphone handset to the local telephone switch use twisted-pair copper wire. Most of\nus have seen twisted pair in our homes and work environments. Twisted pair con-\nsists of two insulated copper wires, each about 1 mm thick, arranged in a regular\nspiral pattern. The wires are twisted together to reduce the electrical interference\nfrom similar pairs close by. Typically, a number of pairs are bundled together in a\ncable by wrapping the pairs in a protective shield. Awire pair constitutes a single\ncommunication link. Unshielded twisted pair (UTP) is commonly used for\ncomputer networks within a building, that is, for LANs. Data rates for LANs\nusing twisted pair today range from 10 Mbps to 10 Gbps. The data rates that can\nbe achieved depend on the thickness of the wire and the distance between trans-\nmitter and receiver.\nWhen fiber-optic technology emerged in the 1980s, many people disparaged\ntwisted pair because of its relatively low bit rates. Some people even felt that fiber-\noptic technology would completely replace twisted pair. But twisted pair did not\ngive up so easily. Modern twisted-pair technology, such as category 6a cable, can\nachieve data rates of 10 Gbps for distances up to a hundred meters. In the end,\ntwisted pair has emerged as the dominant solution for high-speed LAN networking.\nAs discussed earlier, twisted pair is also commonly used for residential Internet\naccess. We saw that dial-up modem technology enables access at rates of up to 56\nkbps over twisted pair. We also saw that DSL(digital subscriber line) technology\nhas enabled residential users to access the Internet at tens of Mbps over twisted pair\n(when users live close to the ISP’s modem).\nCoaxial Cable\nLike twisted pair, coaxial cable consists of two copper conductors, but the two con-\nductors are concentric rather than parallel. With this construction and special insula-\ntion and shielding, coaxial cable can achieve high data transmission rates. Coaxial\ncable is quite common in cable television systems. As we saw earlier, cable televi-\nsion systems have recently been coupled with cable modems to provide residential\nusers with Internet access at rates of tens of Mbps. In cable television and cable\nInternet access, the transmitter shifts the digital signal to a specific frequency band,\nand the resulting analog signal is sent from the transmitter to one or more receivers.\nCoaxial cable can be used as a guided shared medium . Specifically, a number of\nend systems can be connected directly to the cable, with each of the end systems\nreceiving whatever is sent by the other end systems.\nFiber Optics\nAn optical fiber is a thin, flexible medium that conducts pulses of light, with each\npulse representing a bit. Asingle optical fiber can support tremendous bit rates, up\nto tens or even hundreds of gigabits per second. They are immune to electromag-\nnetic interference, have very low signal attenuation up to 100 kilometers, and are\nvery hard to tap. These characteristics have made fiber optics the preferred long-\nhaul guided transmission media, particularly for overseas links. Many of the long-\ndistance telephone networks in the United States and elsewhere now use fiber optics\nexclusively. Fiber optics is also prevalent in the backbone of the Internet. However,\nthe high cost of optical devices—such as transmitters, receivers, and switches—has\nhindered their deployment for short-haul transport, such as in a LAN or into the\nhome in a residential access network. The Optical Carrier (OC) standard link speeds\nrange from 51.8 Mbps to 39.8 Gbps; these specifications are often referred to as OC-\nn , where the link speed equals n × 51.8 Mbps. Standards in use today include OC-1,\nOC-3, OC-12, OC-24, OC-48, OC-96, OC-192, OC-768. [Mukherjee 2006,\nRamaswamy 2010] provide coverage of various aspects of optical networking.\nTerrestrial Radio Channels\nRadio channels carry signals in the electromagnetic spectrum. They are an attractive\nmedium because they require no physical wire to be installed, can penetrate walls,\nprovide connectivity to a mobile user, and can potentially carry a signal for long dis-\ntances. The characteristics of a radio channel depend significantly on the propagation\nenvironment and the distance over which a signal is to be carried. Environmental con-\nsiderations determine path loss and shadow fading (which decrease the signal strength\nas the signal travels over a distance and around/through obstructing objects), multi-\npath fading (due to signal reflection off of interfering objects), and interference (due\nto other transmissions and electromagnetic signals).\nTerrestrial radio channels can be broadly classified into three groups: those that\noperate over very short distance (e.g., with one or two meters); those that operate in\nlocal areas, typically spanning from ten to a few hundred meters; and those that\noperate in the wide area, spanning tens of kilometers. Personal devices such as wire-\nless headsets, keyboards, and medical devices operate over short distances; the\nwireless LAN technologies described in Section 1.2.1 use local-area radio channels;\nthe cellular access technologies use wide-area radio channels. We’ll discuss radio\nchannels in detail in Chapter 6.\nSatellite Radio Channels\nAcommunication satellite links two or more Earth-based microwave transmitter/\nreceivers, known as ground stations. The satellite receives transmissions on one fre-\nquency band, regenerates the signal using a repeater (discussed below), and transmits\nthe signal on another frequency. Two types of satellites are used in communications:\ngeostationary satellites and low-earth orbiting (LEO) satellites .\nGeostationary satellites permanently remain above the same spot on Earth. This\nstationary presence is achieved by placing the satellite in orbit at 36,000 kilometers\nabove Earth’s surface. This huge distance from ground station through satellite back\nto ground station introduces a substantial signal propagation delay of 280 millisec-\nonds. Nevertheless, satellite links, which can operate at speeds of hundreds of Mbps,\nare often used in areas without access to DSLor cable-based Internet access.\nLEO satellites are placed much closer to Earth and do not remain permanently\nabove one spot on Earth. They rotate around Earth (just as the Moon does) and may\ncommunicate with each other, as well as with ground stations. To provide continuous\ncoverage to an area, many satellites need to be placed in orbit. There are currently\nmany low-altitude communication systems in development. Lloyd’s satellite con-\nstellations Web page [Wood 2012] provides and collects information on satellite\nconstellation systems for communications. LEO satellite technology may be used\nfor Internet access sometime in the future.\n"
  },
  {
    "title": "1.3 The Network Core",
    "content": "Having examined the Internet’s edge, let us now delve more deeply inside the net-\nwork core—the mesh of packet switches and links that interconnects the Internet’s\nend systems. Figure 1.10highlights the network core with thick, shaded lines.\n"
  },
  {
    "title": "1.3.1 Packet Switching",
    "content": "In a network application, end systems exchange messages with each other. Mes-\nsages can contain anything the application designer wants. Messages may perform a\ncontrol function (for example, the “Hi” messages in our handshaking example in\naudio file. To send a message from a source end system to a destination end system,\nthe source breaks long messages into smaller chunks of data known as packets .\nBetween source and destination, each packet travels through communication links\nand packet switches (for which there are two predominant types, routers and link-\nlayer switches ). Packets are transmitted over each communication link at a rate\nequal to the full transmission rate of the link. So, if a source end system or a packet\nswitch is sending a packet of L bits over a link with transmission rate R bits/sec, then\nthe time to transmit the packet is L/R seconds.\nStore-and-Forward Transmission\nMost packet switches use store-and-forward transmission at the inputs to the\nlinks. Store-and-forward transmission means that the packet switch must receive\nthe entire packet before it can begin to transmit the first bit of the packet onto the\noutbound link. To explore store-and-forward transmission in more detail, consider\na simple network consisting of two end systems connected by a single router, as\nshown in Figure 1.11. Arouter will typically have many incident links, since its job\nis to switch an incoming packet onto an outgoing link; in this simple example, the\nrouter has the rather simple task of transferring a packet from one (input) link to\nthe only other attached link. In this example, the source has three packets, each\nconsisting of L bits, to send to the destination. At the snapshot of time shown in\nhas already arrived at the router. Because the router employs store-and-forwarding,\nNational or\nGlobal ISP\nLocal or\nRegional ISP\nEnterprise Network\nHome Network\nMobile Network\nmust first buffer (i.e., “store”) the packet’s bits. Only after the router has received\nall of the packet’s bits can it begin to transmit (i.e., “forward”) the packet onto the\noutbound link. To gain some insight into store-and-forward transmission, let’s now\ncalculate the amount of time that elapses from when the source begins to send the\npacket until the destination has received the entire packet. (Here we will ignore\npropagation delay—the time it takes for the bits to travel across the wire at near the\nspeed of light—which will be discussed in Section 1.4.) The source begins to trans-\nmit at time 0; at time L / R seconds, the source has transmitted the entire packet, and\nthe entire packet has been received and stored at the router (since there is no propa-\ngation delay). At time L / R seconds, since the router has just received the entire\npacket, it can begin to transmit the packet onto the outbound link towards the desti-\nnation; at time 2 L / R , the router has transmitted the entire packet, and the entire\npacket has been received by the destination. Thus, the total delay is 2 L / R . If\nthe switch instead forwarded bits as soon as they arrive (without first receiving the\nentire packet), then the total delay would be L / R since bits are not held up at\nthe router. But, as we will discuss in Section 1.4, routers need to receive, store, and\nprocess the entire packet before forwarding.\nNow let’s calculate the amount of time that elapses from when the source\nbegins to send the first packet until the destination has received all three packets.\nAs before, at time L / R , the router begins to forward the first packet. But also at time\nL / R the source will begin to send the second packet, since it has just finished send-\ning the entire first packet. Thus, at time 2 L / R , the destination has received the first\npacket and the router has received the second packet. Similarly, at time 3 L / R , the\ndestination has received the first two packets and the router has received the third\npacket. Finally, at time 4 L / R the destination has received all three packets!\nLet’s now consider the general case of sending one packet from source to desti-\nnation over a path consisting of N links each of rate R (thus, there are N -1 routers\nbetween source and destination). Applying the same logic as above, we see that the\nend-to-end delay is:\n(1.1)\nd end @ to @ end\n= N\nL\nR\nSource\nR bps\nFront of packet 1 Destination\nstored in router,\nawaiting remaining\nbits before forwarding\nQueuing Delays and Packet Loss\nEach packet switch has multiple links attached to it. For each attached link, the\npacket switch has an output buffer (also called an output queue ), which stores\npackets that the router is about to send into that link. The output buffers play a key\nrole in packet switching. If an arriving packet needs to be transmitted onto a link but\nfinds the link busy with the transmission of another packet, the arriving packet must\nwait in the output buffer. Thus, in addition to the store-and-forward delays, packets\nsuffer output buffer queuing delays . These delays are variable and depend on the\nlevel of congestion in the network. Since the amount of buffer space is finite, an\narriving packet may find that the buffer is completely full with other packets wait-\ning for transmission. In this case, packet loss will occur—either the arriving packet\nor one of the already-queued packets will be dropped.\npackets are represented by three-dimensional slabs. The width of a slab represents\nthe number of bits in the packet. In this figure, all packets have the same width and\nhence the same length. Suppose Hosts Aand B are sending packets to Host E. Hosts\nAand B first send their packets along 10 Mbps Ethernet links to the first router. The\nrouter then directs these packets to the 1.5 Mbps link. If, during a short interval of\ntime, the arrival rate of packets to the router (when converted to bits per second)\nexceeds 1.5 Mbps, congestion will occur at the router as packets queue in the link’s\noutput buffer before being transmitted onto the link. For example, if Host Aand B\neach send a burst of five packets back-to-back at the same time, then most of these\npackets will spend some time waiting in the queue. The situation is, in fact, entirely\nanalogous to many common-day situations—for example, when we wait in line for\na bank teller or wait in front of a tollbooth. We’ll examine this queuing delay in\nmore detail in Section 1.4.\n10 Mbps Ethernet\nKey:\nPackets\nA\nB\nC\nD E\n1.5 Mbps\nQueue of\npackets waiting\nfor output link\nForwarding Tables and Routing Protocols\nEarlier, we said that a router takes a packet arriving on one of its attached\ncommunication links and forwards that packet onto another one of its attached com-\nmunication links. But how does the router determine which link it should forward\nthe packet onto? Packet forwarding is actually done in different ways in different\ntypes of computer networks. Here, we briefly describe how it is done in the\nInternet.\nIn the Internet, every end system has an address called an IPaddress. When a\nsource end system wants to send a packet to a destination end system, the source\nincludes the destination’s IPaddress in the packet’s header. As with postal addresses,\nthis address has a hierarchical structure. When a packet arrives at a router in the\nnetwork, the router examines a portion of the packet’s destination address and for-\nwards the packet to an adjacent router. More specifically, each router has a\nforwarding table that maps destination addresses (or portions of the destination\naddresses) to that router’s outbound links. When a packet arrives at a router, the\nrouter examines the address and searches its forwarding table, using this destination\naddress, to find the appropriate outbound link. The router then directs the packet to\nthis outbound link.\nThe end-to-end routing process is analogous to a car driver who does not use\nmaps but instead prefers to ask for directions. For example, suppose Joe is driving\nfrom Philadelphia to 156 Lakeside Drive in Orlando, Florida. Joe first drives to his\nneighborhood gas station and asks how to get to 156 Lakeside Drive in Orlando,\nFlorida. The gas station attendant extracts the Florida portion of the address and\ntells Joe that he needs to get onto the interstate highway I-95 South, which has an\nentrance just next to the gas station. He also tells Joe that once he enters Florida,\nhe should ask someone else there. Joe then takes I-95 South until he gets to Jack-\nsonville, Florida, at which point he asks another gas station attendant for directions.\nThe attendant extracts the Orlando portion of the address and tells Joe that he\nshould continue on I-95 to Daytona Beach and then ask someone else. In Daytona\nBeach, another gas station attendant also extracts the Orlando portion of the\naddress and tells Joe that he should take I-4 directly to Orlando. Joe takes I-4 and\ngets off at the Orlando exit. Joe goes to another gas station attendant, and this time\nthe attendant extracts the Lakeside Drive portion of the address and tells Joe the\nroad he must follow to get to Lakeside Drive. Once Joe reaches Lakeside Drive, he\nasks a kid on a bicycle how to get to his destination. The kid extracts the 156 por-\ntion of the address and points to the house. Joe finally reaches his ultimate destina-\ntion. In the above analogy, the gas station attendants and kids on bicycles are\nanalogous to routers.\nWe just learned that a router uses a packet’s destination address to index a for-\nwarding table and determine the appropriate outbound link. But this statement begs\nyet another question: How do forwarding tables get set? Are they configured by\nhand in each and every router, or does the Internet use a more automated procedure?\nThis issue will be studied in depth in Chapter 4. But to whet your appetite here,\nwe’ll note now that the Internet has a number of special routing protocols that are\nused to automatically set the forwarding tables. Arouting protocol may, for exam-\nple, determine the shortest path from each router to each destination and use the\nshortest path results to configure the forwarding tables in the routers.\nHow would you actually like to see the end-to-end route that packets take in the\nInternet? We now invite you to get your hands dirty by interacting with the Trace-\nroute program. Simply visit the site www.traceroute.org, choose a source in a particu-\nlar country, and trace the route from that source to your computer. (For a discussion of\nTraceroute, see Section 1.4.)\n"
  },
  {
    "title": "1.3.2 Circuit Switching",
    "content": "There are two fundamental approaches to moving data through a network of links\nand switches: circuit switching and packet switching . Having covered packet-\nswitched networks in the previous subsection, we now turn our attention to circuit-\nswitched networks.\nIn circuit-switched networks, the resources needed along a path (buffers, link\ntransmission rate) to provide for communication between the end systems are\nreserved for the duration of the communication session between the end systems. In\npacket-switched networks, these resources are not reserved; a session’s messages\nuse the resources on demand, and as a consequence, may have to wait (that is,\nqueue) for access to a communication link. As a simple analogy, consider two\nrestaurants, one that requires reservations and another that neither requires reserva-\ntions nor accepts them. For the restaurant that requires reservations, we have to go\nthrough the hassle of calling before we leave home. But when we arrive at the\nrestaurant we can, in principle, immediately be seated and order our meal. For the\nrestaurant that does not require reservations, we don’t need to bother to reserve a\nwe can be seated.\nTraditional telephone networks are examples of circuit-switched networks.\nConsider what happens when one person wants to send information (voice or fac-\nsimile) to another over a telephone network. Before the sender can send the infor-\nmation, the network must establish a connection between the sender and the\nreceiver. This is a bona fide connection for which the switches on the path\nbetween the sender and receiver maintain connection state for that connection. In\nthe jargon of telephony, this connection is called a circuit . When the network\nestablishes the circuit, it also reserves a constant transmission rate in the net-\nwork’s links (representing a fraction of each link’s transmission capacity) for the\nduration of the connection. Since a given transmission rate has been reserved for\nthis sender-to-receiver connection, the sender can transfer the data to the receiver\nat the guaranteed constant rate.\ncuit switches are interconnected by four links. Each of these links has four circuits,\nso that each link can support four simultaneous connections. The hosts (for exam-\nple, PCs and workstations) are each directly connected to one of the switches. When\ntwo hosts want to communicate, the network establishes a dedicated end-to-end\nconnection between the two hosts. Thus, in order for Host Ato communicate with\nHost B, the network must first reserve one circuit on each of two links. In this exam-\nple, the dedicated end-to-end connection uses the second circuit in the first link and\nthe fourth circuit in the second link. Because each link has four circuits, for each\nlink used by the end-to-end connection, the connection gets one fourth of the link’s\ntotal transmission capacity for the duration of the connection. Thus, for example, if\neach link between adjacent switches has a transmission rate of 1 Mbps, then each\nend-to-end circuit-switch connection gets 250 kbps of dedicated transmission rate.\nIn contrast, consider what happens when one host wants to send a packet to\nanother host over a packet-switched network, such as the Internet. As with circuit\nswitching, the packet is transmitted over a series of communication links. But different\nfrom circuit switching, the packet is sent into the network without reserving any link\nresources whatsoever. If one of the links is congested because other packets need to be\ntransmitted over the link at the same time, then the packet will have to wait in a buffer\nat the sending side of the transmission link and suffer a delay. The Internet makes its\nbest effort to deliver packets in a timely manner, but it does not make any guarantees.\nMultiplexing in Circuit-Switched Networks\nAcircuit in a link is implemented with either frequency-division multiplexing\n(FDM) or time-division multiplexing (TDM) . With FDM, the frequency spec-\ntrum of a link is divided up among the connections established across the link.\nSpecifically, the link dedicates a frequency band to each connection for the\nduration of the connection. In telephone networks, this frequency band typically\nhas a width of 4 kHz (that is, 4,000 hertz or 4,000 cycles per second). The width\nof the band is called, not surprisingly, the bandwidth . FM radio stations also use\nFDM to share the frequency spectrum between 88 MHz and 108 MHz, with each\nstation being allocated a specific frequency band.\nFor a TDM link, time is divided into frames of fixed duration, and each frame\nis divided into a fixed number of time slots. When the network establishes a connec-\ntion across a link, the network dedicates one time slot in every frame to this connec-\ntion. These slots are dedicated for the sole use of that connection, with one time slot\navailable for use (in every frame) to transmit the connection’s data.\nto four circuits. For FDM, the frequency domain is segmented into four bands, each\nof bandwidth 4 kHz. For TDM, the time domain is segmented into frames, with four\ntime slots in each frame; each circuit is assigned the same dedicated slot in the\nrevolving TDM frames. For TDM, the transmission rate of a circuit is equal to the\nframe rate multiplied by the number of bits in a slot. For example, if the link trans-\nmits 8,000 frames per second and each slot consists of 8 bits, then the transmission\nrate of a circuit is 64 kbps.\nProponents of packet switching have always argued that circuit switching is\nwasteful because the dedicated circuits are idle during silent periods . For example,\n4KHz\nTDM\nFDM\nLink Frequency\n4KHz\nSlot\nKey:\nAll slots labeled “2” are dedicated\nto a specific sender-receiver pair.\nFrame\n2 3 4 1 2 3 4 1 2 3 4 1 2 3 4\nTime\nbandwidth. With TDM, each circuit gets all of the bandwidth\nwhen one person in a telephone call stops talking, the idle network resources (fre-\nquency bands or time slots in the links along the connection’s route) cannot be used\nby other ongoing connections. As another example of how these resources can be\nunderutilized, consider a radiologist who uses a circuit-switched network to\nremotely access a series of x-rays. The radiologist sets up a connection, requests an\nimage, contemplates the image, and then requests a new image. Network resources\nare allocated to the connection but are not used (i.e., are wasted) during the radiolo-\ngist’s contemplation periods. Proponents of packet switching also enjoy pointing out\nthat establishing end-to-end circuits and reserving end-to-end transmission capacity\nis complicated and requires complex signaling software to coordinate the operation\nof the switches along the end-to-end path.\nBefore we finish our discussion of circuit switching, let’s work through a numeri-\ncal example that should shed further insight on the topic. Let us consider how long it\ntakes to send a file of 640,000 bits from Host Ato Host B over a circuit-switched net-\nwork. Suppose that all links in the network use TDM with 24 slots and have a bit rate\nof 1.536 Mbps. Also suppose that it takes 500 msec to establish an end-to-end circuit\nbefore Host Acan begin to transmit the file. How long does it take to send the file?\nEach circuit has a transmission rate of (1.536 Mbps)/24 = 64 kbps, so it takes (640,000\nbits)/(64 kbps) = 10 seconds to transmit the file. To this 10 seconds we add the circuit\nestablishment time, giving 10.5 seconds to send the file. Note that the transmission\ntime is independent of the number of links: The transmission time would be 10 sec-\nonds if the end-to-end circuit passed through one link or a hundred links. (The actual\nend-to-end delay also includes a propagation delay; see Section 1.4.)\nPacket Switching Versus Circuit Switching\nHaving described circuit switching and packet switching, let us compare the two.\nCritics of packet switching have often argued that packet switching is not suitable\nfor real-time services (for example, telephone calls and video conference calls)\nbecause of its variable and unpredictable end-to-end delays (due primarily to vari-\nable and unpredictable queuing delays). Proponents of packet switching argue that\n(1) it offers better sharing of transmission capacity than circuit switching and (2) it\nis simpler, more efficient, and less costly to implement than circuit switching. An\ninteresting discussion of packet switching versus circuit switching is [Molinero-\nFernandez 2002]. Generally speaking, people who do not like to hassle with restau-\nrant reservations prefer packet switching to circuit switching.\nWhy is packet switching more efficient? Let’s look at a simple example. Sup-\npose users share a 1 Mbps link. Also suppose that each user alternates between peri-\nods of activity, when a user generates data at a constant rate of 100 kbps, and periods\nof inactivity, when a user generates no data. Suppose further that a user is active\nonly 10 percent of the time (and is idly drinking coffee during the remaining 90 per-\ncent of the time). With circuit switching, 100 kbps must be reserved for each user at\nall times. For example, with circuit-switched TDM, if a one-second frame is divided\ninto 10 time slots of 100 ms each, then each user would be allocated one time slot\nper frame.\nThus, the circuit-switched link can support only 10 (= 1 Mbps/100 kbps) simul-\ntaneous users. With packet switching, the probability that a specific user is active is\n0.1 (that is, 10 percent). If there are 35 users, the probability that there are 11 or\nmore simultaneously active users is approximately 0.0004. (Homework Problem P8\noutlines how this probability is obtained.) When there are 10 or fewer simultane-\nously active users (which happens with probability 0.9996), the aggregate arrival\nrate of data is less than or equal to 1 Mbps, the output rate of the link. Thus, when\nthere are 10 or fewer active users, users’packets flow through the link essentially\nwithout delay, as is the case with circuit switching. When there are more than 10\nsimultaneously active users, then the aggregate arrival rate of packets exceeds the\noutput capacity of the link, and the output queue will begin to grow. (It continues to\ngrow until the aggregate input rate falls back below 1 Mbps, at which point the\nqueue will begin to diminish in length.) Because the probability of having more than\n10 simultaneously active users is minuscule in this example, packet switching pro-\nvides essentially the same performance as circuit switching, but does so while\nallowing for more than three times the number of users.\nLet’s now consider a second simple example. Suppose there are 10 users and that\none user suddenly generates one thousand 1,000-bit packets, while other users\nremain quiescent and do not generate packets. Under TDM circuit switching with 10\nslots per frame and each slot consisting of 1,000 bits, the active user can only use its\none time slot per frame to transmit data, while the remaining nine time slots in each\nframe remain idle. It will be 10 seconds before all of the active user’s one million bits\nof data has been transmitted. In the case of packet switching, the active user can con-\ntinuously send its packets at the full link rate of 1 Mbps, since there are no other users\ngenerating packets that need to be multiplexed with the active user’s packets. In this\ncase, all of the active user’s data will be transmitted within 1 second.\nThe above examples illustrate two ways in which the performance of packet\nswitching can be superior to that of circuit switching. They also highlight the crucial\ndifference between the two forms of sharing a link’s transmission rate among multi-\nple data streams. Circuit switching pre-allocates use of the transmission link regard-\nless of demand, with allocated but unneeded link time going unused. Packet\nswitching on the other hand allocates link use on demand. Link transmission capac-\nity will be shared on a packet-by-packet basis only among those users who have\npackets that need to be transmitted over the link.\nAlthough packet switching and circuit switching are both prevalent in today’s\ntelecommunication networks, the trend has certainly been in the direction of packet\nswitching. Even many of today’s circuit-switched telephone networks are slowly\nmigrating toward packet switching. In particular, telephone networks often use\npacket switching for the expensive overseas portion of a telephone call.\n"
  },
  {
    "title": "1.3.3 A Network of Networks",
    "content": "We saw earlier that end systems (PCs, smartphones, Web servers, mail servers,\nand so on) connect into the Internet via an access ISP. The access ISPcan pro-\nvide either wired or wireless connectivity, using an array of access technologies\nincluding DSL, cable, FTTH, Wi-Fi, and cellular. Note that the access ISPdoes\nnot have to be a telco or a cable company; instead it can be, for example, a uni-\nversity (providing Internet access to students, staff, and faculty), or a company\n(providing access for its employees). But connecting end users and content\nproviders into an access ISPis only a small piece of solving the puzzle of con-\nnecting the billions of end systems that make up the Internet. To complete this\npuzzle, the access ISPs themselves must be interconnected. This is done by cre-\nating a network of networks —understanding this phrase is the key to understand-\ning the Internet.\nOver the years, the network of networks that forms the Internet has evolved into\na very complex structure. Much of this evolution is driven by economics and\nnational policy, rather than by performance considerations. In order to understand\ntoday’s Internet network structure, let’s incrementally build a series of network\nstructures, with each new structure being a better approximation of the complex\nInternet that we have today. Recall that the overarching goal is to interconnect the\naccess ISPs so that all end systems can send packets to each other. One naive\napproach would be to have each access ISP directly connect with every other access\nISP. Such a mesh design is, of course, much too costly for the access ISPs, as it\nwould require each access ISPto have a separate communication link to each of the\nhundreds of thousands of other access ISPs all over the world.\nOur first network structure, Network Structure 1 , interconnects all of the\naccess ISPs with a singleglobal transit ISP . Our (imaginary) global transit ISPis\na network of routers and communication links that not only spans the globe, but\nalso has at least one router near each of the hundreds of thousands of access ISPs.\nOf course, it would be very costly for the global ISPto build such an extensive\nnetwork. To be profitable, it would naturally charge each of the access ISPs for\nconnectivity, with the pricing reflecting (but not necessarily directly proportional\nto) the amount of traffic an access ISPexchanges with the global ISP. Since the\naccess ISPpays the global transit ISP, the access ISPis said to be a customer and\nthe global transit ISPis said to be a provider .\nNow if some company builds and operates a global transit ISPthat is profitable,\nthen it is natural for other companies to build their own global transit ISPs and com-\npete with the original global transit ISP. This leads to Network Structure 2 , which\nconsists of the hundreds of thousands of access ISPs and multiple global transit\nISPs. The access ISPs certainly prefer Network Structure 2 over Network Structure\n1 since they can now choose among the competing global transit providers as a\nfunction of their pricing and services. Note, however, that the global transit ISPs\nthemselves must interconnect: Otherwise access ISPs connected to one of the global\ntransit providers would not be able to communicate with access ISPs connected to\nthe other global transit providers.\nNetwork Structure 2, just described, is a two-tier hierarchy with global transit\nproviders residing at the top tier and access ISPs at the bottom tier. This assumes\nthat global transit ISPs are not only capable of getting close to each and every access\nISP, but also find it economically desirable to do so. In reality, although some ISPs\ndo have impressive global coverage and do directly connect with many access ISPs,\nno ISPhas presence in each and every city in the world. Instead, in any given region,\nthere may be a regional ISP to which the access ISPs in the region connect. Each\nregional ISPthen connects to tier-1 ISPs . Tier-1 ISPs are similar to our (imaginary)\nglobal transit ISP; but tier-1 ISPs, which actually do exist, do not have a presence in\nevery city in the world. There are approximately a dozen tier-1 ISPs, including\nLevel 3 Communications, AT&T, Sprint, and NTT. Interestingly, no group officially\nsanctions tier-1 status; as the saying goes—if you have to ask if you’re a member of\na group, you’re probably not.\nReturning to this network of networks, not only are there multiple competing tier-\n1 ISPs, there may be multiple competing regional ISPs in a region. In such a hierar-\nchy, each access ISPpays the regional ISPto which it connects, and each regional ISP\npays the tier-1 ISPto which it connects. (An access ISPcan also connect directly to a\ntier-1 ISP, in which case it pays the tier-1 ISP). Thus, there is customer-provider\nrelationship at each level of the hierarchy. Note that the tier-1 ISPs do not pay anyone\nas they are at the top of the hierarchy. To further complicate matters, in some regions,\nthere may be a larger regional ISP(possibly spanning an entire country) to which the\nsmaller regional ISPs in that region connect; the larger regional ISPthen connects to a\ntier-1 ISP. For example, in China, there are access ISPs in each city, which connect to\nprovincial ISPs, which in turn connect to national ISPs, which finally connect to tier-1\nISPs [Tian 2012]. We refer to this multi-tier hierarchy, which is still only a crude\napproximation of today’s Internet, as Network Structure 3 .\nTo build a network that more closely resembles today’s Internet, we must add\npoints of presence (PoPs), multi-homing, peering, and Internet exchange points\n(IXPs) to the hierarchical Network Structure 3. PoPs exist in all levels of the hier-\narchy, except for the bottom (access ISP) level. A PoP is simply a group of one or\nmore routers (at the same location) in the provider’s network where customer ISPs\ncan connect into the provider ISP. For a customer network to connect to a\nprovider’s PoP, it can lease a high-speed link from a third-party telecommunica-\ntions provider to directly connect one of its routers to a router at the PoP. Any ISP\n(except for tier-1 ISPs) may choose to multi-home , that is, to connect to two or\nmore provider ISPs. So, for example, an access ISP may multi-home with two\nregional ISPs, or it may multi-home with two regional ISPs and also with a tier-1\nISP. Similarly, a regional ISPmay multi-home with multiple tier-1 ISPs. When an\nISPmulti-homes, it can continue to send and receive packets into the Internet even\nif one of its providers has a failure.\nAs we just learned, customer ISPs pay their provider ISPs to obtain global\nInternet interconnectivity. The amount that a customer ISP pays a provider ISP\nreflects the amount of traffic it exchanges with the provider. To reduce these costs, a\npair of nearby ISPs at the same level of the hierarchy can peer , that is, they can\ndirectly connect their networks together so that all the traffic between them passes\nover the direct connection rather than through upstream intermediaries. When two\nISPs peer, it is typically settlement-free, that is, neither ISPpays the other. As noted\nearlier, tier-1 ISPs also peer with one another, settlement-free. For a readable dis-\ncussion of peering and customer-provider relationships, see [Van der Berg 2008].\nAlong these same lines, a third-party company can create an Internet Exchange\nPoint (IXP) (typically in a stand-alone building with its own switches), which is a\nmeeting point where multiple ISPs can peer together. There are roughly 300 IXPs in\nthe Internet today [Augustin 2009]. We refer to this ecosystem—consisting of\naccess ISPs, regional ISPs, tier-1 ISPs, PoPs, multi-homing, peering, and IXPs—as\nNetwork Structure 4 .\nWe now finally arrive at Network Structure 5, which describes the Internet of\n2012. Network Structure 5, illustrated in Figure 1.15, builds on top of Network\nStructure 4 by adding content providernetworks . Google is currently one of the\nleading examples of such a content provider network. As of this writing, it is esti-\nmated that Google has 30 to 50 data centers distributed across North America,\nEurope, Asia, South America, and Australia. Some of these data centers house\nover one hundred thousand servers, while other data centers are smaller, housing\nonly hundreds of servers. The Google data centers are all interconnected via\nGoogle’s private TCP/IPnetwork, which spans the entire globe but is nevertheless\nseparate from the public Internet. Importantly, the Google private network only\naccess\nISP\naccess\nISP\naccess\nISP\naccess\nISP\naccess\nISP\naccess\nISP\naccess\nISP\naccess\nISP\nRegional\nISP\nTier 1\nISP\nContent provider\n(e.g., Google)\nTier 1\nISP\nIXP\nRegional\nISP\nIXP IXP\ncarries traffic to/from Google servers. As shown in Figure 1.15, the Google\nprivate network attempts to “bypass” the upper tiers of the Internet by peering\n(settlement free) with lower-tier ISPs, either by directly connecting with them or\nby connecting with them at IXPs [Labovitz 2010]. However, because many access\nISPs can still only be reached by transiting through tier-1 networks, the Google\nnetwork also connects to tier-1 ISPs, and pays those ISPs for the traffic it\nexchanges with them. By creating its own network, a content provider not only\nreduces its payments to upper-tier ISPs, but also has greater control of how its\nservices are ultimately delivered to end users. Google’s network infrastructure is\ndescribed in greater detail in Section 7.2.4.\nIn summary, today’s Internet—a network of networks—is complex, consisting of\na dozen or so tier-1 ISPs and hundreds of thousands of lower-tier ISPs. The ISPs are\ndiverse in their coverage, with some spanning multiple continents and oceans, and\nothers limited to narrow geographic regions. The lower-tier ISPs connect to the\nhigher-tier ISPs, and the higher-tier ISPs interconnect with one another. Users and\ncontent providers are customers of lower-tier ISPs, and lower-tier ISPs are customers\nof higher-tier ISPs. In recent years, major content providers have also created their\nown networks and connect directly into lower-tier ISPs where possible.\n"
  },
  {
    "title": "1.4 Delay, Loss, and Throughput",
    "content": "in Packet-Switched Networks\nBack in Section 1.1 we said that the Internet can be viewed as an infrastructure\nthat provides services to distributed applications running on end systems. Ideally,\nwe would like Internet services to be able to move as much data as we want\nbetween any two end systems, instantaneously, without any loss of data. Alas, this\nis a lofty goal, one that is unachievable in reality. Instead, computer networks nec-\nessarily constrain throughput (the amount of data per second that can be trans-\nferred) between end systems, introduce delays between end systems, and can\nactually lose packets. On one hand, it is unfortunate that the physical laws of real-\nity introduce delay and loss as well as constrain throughput. On the other hand,\nbecause computer networks have these problems, there are many fascinating\nissues surrounding how to deal with the problems—more than enough issues to\nfill a course on computer networking and to motivate thousands of PhD theses! In\nthis section, we’ll begin to examine and quantify delay, loss, and throughput in\ncomputer networks.\n"
  },
  {
    "title": "1.4.1 Overview of Delay in Packet-Switched Networks",
    "content": "Recall that a packet starts in a host (the source), passes through a series of routers,\nand ends its journey in another host (the destination). As a packet travels from one\npacket suffers from several types of delays at each node along the path. The most\nimportant of these delays are the nodal processing delay, queuing delay, transmis-\nsion delay, and propagation delay ; together, these delays accumulate to give a total\nnodal delay . The performance of many Internet applications—such as search, Web\nbrowsing, email, maps, instant messaging, and voice-over-IP—are greatly affected\nby network delays. In order to acquire a deep understanding of packet switching and\ncomputer networks, we must understand the nature and importance of these delays.\n"
  },
  {
    "title": "Types of Delay",
    "content": "Let’s explore these delays in the context of Figure 1.16. As part of its end-to-end\nroute between source and destination, a packet is sent from the upstream node\nthrough router Ato router B. Our goal is to characterize the nodal delay at router A.\nNote that router Ahas an outbound link leading to router B. This link is preceded by\na queue (also known as a buffer). When the packet arrives at router Afrom the\nupstream node, router Aexamines the packet’s header to determine the appropriate\noutbound link for the packet and then directs the packet to this link. In this example,\nthe outbound link for the packet is the one that leads to router B. Apacket can be\ntransmitted on a link only if there is no other packet currently being transmitted on\nthe link and if there are no other packets preceding it in the queue; if the link is\ncurrently busy or if there are other packets already queued for the link, the newly\narriving packet will then join the queue.\nProcessing Delay\nThe time required to examine the packet’s header and determine where to direct the\npacket is part of the processing delay . The processing delay can also include other\nfactors, such as the time needed to check for bit-level errors in the packet that occurred\nA\nB\nNodal\nprocessing\nQueueing\n(waiting for\ntransmission)\nTransmission\nPropagation\nin high-speed routers are typically on the order of microseconds or less. After this\nnodal processing, the router directs the packet to the queue that precedes the link to\nrouter B. (In Chapter 4we’ll study the details of how a router operates.)\nQueuing Delay\nAt the queue, the packet experiences a queuing delay as it waits to be transmitted onto\nthe link. The length of the queuing delay of a specific packet will depend on the num-\nber of earlier-arriving packets that are queued and waiting for transmission onto the\nlink. If the queue is empty and no other packet is currently being transmitted, then our\npacket’s queuing delay will be zero. On the other hand, if the traffic is heavy and many\nother packets are also waiting to be transmitted, the queuing delay will be long. We\nwill see shortly that the number of packets that an arriving packet might expect to find\nis a function of the intensity and nature of the traffic arriving at the queue. Queuing\ndelays can be on the order of microseconds to milliseconds in practice.\nTransmission Delay\nAssuming that packets are transmitted in a first-come-first-served manner, as is com-\nmon in packet-switched networks, our packet can be transmitted only after all the\npackets that have arrived before it have been transmitted. Denote the length of the\npacket by L bits, and denote the transmission rate of the link from router Ato router\nB by R bits/sec. For example, for a 10 Mbps Ethernet link, the rate is R = 10 Mbps;\nfor a 100 Mbps Ethernet link, the rate is R = 100 Mbps. The transmission delay is\nL/R. This is the amount of time required to push (that is, transmit) all of the packet’s\nbits into the link. Transmission delays are typically on the order of microseconds to\nmilliseconds in practice.\nPropagation Delay\nOnce a bit is pushed into the link, it needs to propagate to router B. The time\nrequired to propagate from the beginning of the link to router B is the propagation\ndelay . The bit propagates at the propagation speed of the link. The propagation\nspeed depends on the physical medium of the link (that is, fiber optics, twisted-pair\ncopper wire, and so on) and is in the range of\n2  10 8 meters/sec to 3  10 8 meters/sec\nwhich is equal to, or a little less than, the speed of light. The propagation delay is\nthe distance between two routers divided by the propagation speed. That is, the\npropagation delay is d/s, where d is the distance between router Aand router B and s\nis the propagation speed of the link. Once the last bit of the packet propagates to\nprocess then continues with router B now performing the forwarding. In wide-area\nnetworks, propagation delays are on the order of milliseconds.\nComparing Transmission and Propagation Delay\nNewcomers to the field of computer networking sometimes have difficulty under-\nstanding the difference between transmission delay and propagation delay. The differ-\nence is subtle but important. The transmission delay is the amount of time required for\nthe router to push out the packet; it is a function of the packet’s length and the trans-\nmission rate of the link, but has nothing to do with the distance between the two\nrouters. The propagation delay, on the other hand, is the time it takes a bit to propagate\nfrom one router to the next; it is a function of the distance between the two routers, but\nhas nothing to do with the packet’s length or the transmission rate of the link.\nAn analogy might clarify the notions of transmission and propagation delay. Con-\nsider a highway that has a tollbooth every 100 kilometers, as shown in Figure 1.17.\nYou can think of the highway segments between tollbooths as links and the toll-\nbooths as routers. Suppose that cars travel (that is, propagate) on the highway at a\nrate of 100 km/hour (that is, when a car leaves a tollbooth, it instantaneously accel-\nerates to 100 km/hour and maintains that speed between tollbooths). Suppose next\nthat 10 cars, traveling together as a caravan, follow each other in a fixed order. You\ncan think of each car as a bit and the caravan as a packet. Also suppose that each\ntollbooth services (that is, transmits) a car at a rate of one car per 12 seconds, and\nthat it is late at night so that the caravan’s cars are the only cars on the highway.\nFinally, suppose that whenever the first car of the caravan arrives at a tollbooth, it\nwaits at the entrance until the other nine cars have arrived and lined up behind it.\n(Thus the entire caravan must be stored at the tollbooth before it can begin to be for-\nwarded.) The time required for the tollbooth to push the entire caravan onto the\nhighway is (10 cars)/(5 cars/minute) = 2 minutes. This time is analogous to the\ntransmission delay in a router. The time required for a car to travel from the exit of\none tollbooth to the next tollbooth is 100 km/(100 km/hour) = 1 hour. This time is\nanalogous to propagation delay. Therefore, the time from when the caravan is stored\nin front of a tollbooth until the caravan is stored in front of the next tollbooth is the\nsum of transmission delay and propagation delay—in this example, 62 minutes.\nTen-car\ncaravan\nToll\nbooth\nToll\nbooth\n100 km 100 km\nLet’s explore this analogy a bit more. What would happen if the tollbooth service\ntime for a caravan were greater than the time for a car to travel between tollbooths?\nFor example, suppose now that the cars travel at the rate of 1,000 km/hour and the toll-\nbooth services cars at the rate of one car per minute. Then the traveling delay between\ntwo tollbooths is 6 minutes and the time to serve a caravan is 10 minutes. In this case,\nthe first few cars in the caravan will arrive at the second tollbooth before the last cars\nin the caravan leave the first tollbooth. This situation also arises in packet-switched\nnetworks—the first bits in a packet can arrive at a router while many of the remaining\nbits in the packet are still waiting to be transmitted by the preceding router.\nIf a picture speaks a thousand words, then an animation must speak a million\nwords. The companion Web site for this textbook provides an interactive Java applet\nthat nicely illustrates and contrasts transmission delay and propagation delay. The\nreader is highly encouraged to visit that applet. [Smith 2009] also provides a very\nreadable discussion of propagation, queueing, and transmission delays.\nIf we let d\nproc\n, d\nqueue\n, d\ntrans\n, and d\nprop\ndenote the processing, queuing, transmis-\nsion, and propagation delays, then the total nodal delay is given by\nd\nnodal\n= d\nproc\n+ d\nqueue\n+ d\ntrans\n+ d\nprop\nThe contribution of these delay components can vary significantly. For example,\nd\nprop\ncan be negligible (for example, a couple of microseconds) for a link connect-\ning two routers on the same university campus; however, d\nprop\nis hundreds of mil-\nliseconds for two routers interconnected by a geostationary satellite link, and can be\nthe dominant term in d\nnodal\n. Similarly, d\ntrans\ncan range from negligible to significant.\nIts contribution is typically negligible for transmission rates of 10 Mbps and higher\n(for example, for LANs); however, it can be hundreds of milliseconds for large\nInternet packets sent over low-speed dial-up modem links. The processing delay,\nd\nproc\n, is often negligible; however, it strongly influences a router’s maximum\nthroughput, which is the maximum rate at which a router can forward packets.\n"
  },
  {
    "title": "1.4.2 Queuing Delay and Packet Loss",
    "content": "The most complicated and interesting component of nodal delay is the queuing\ndelay, d\nqueue\n. In fact, queuing delay is so important and interesting in computer net-\nworking that thousands of papers and numerous books have been written about it\n[Bertsekas 1991; Daigle 1991; Kleinrock 1975, 1976; Ross 1995]. We give only a\nhigh-level, intuitive discussion of queuing delay here; the more curious reader may\nwant to browse through some of the books (or even eventually write a PhD thesis\non the subject!). Unlike the other three delays (namely, d\nproc\n, d\ntrans\n, and d\nprop\n), the\nqueuing delay can vary from packet to packet. For example, if 10 packets arrive\nat an empty queue at the same time, the first packet transmitted will suffer no queu-\ning delay, while the last packet transmitted will suffer a relatively large queuing\ncharacterizing queuing delay, one typically uses statistical measures, such as aver-\nage queuing delay, variance of queuing delay, and the probability that the queuing\ndelay exceeds some specified value.\nWhen is the queuing delay large and when is it insignificant? The answer to this\nquestion depends on the rate at which traffic arrives at the queue, the transmission\nrate of the link, and the nature of the arriving traffic, that is, whether the traffic arrives\nperiodically or arrives in bursts. To gain some insight here, let a denote the average\nrate at which packets arrive at the queue ( a is in units of packets/sec). Recall that R is\nthe transmission rate; that is, it is the rate (in bits/sec) at which bits are pushed out of\nthe queue. Also suppose, for simplicity, that all packets consist of L bits. Then the\naverage rate at which bits arrive at the queue is La bits/sec. Finally, assume that the\nqueue is very big, so that it can hold essentially an infinite number of bits. The ratio\nLa/R, called the traffic intensity , often plays an important role in estimating the\nextent of the queuing delay. If La/R > 1, then the average rate at which bits arrive at\nthe queue exceeds the rate at which the bits can be transmitted from the queue. In this\nunfortunate situation, the queue will tend to increase without bound and the queuing\ndelay will approach infinity! Therefore, one of the golden rules in traffic engineering\nis: Design your system so that the traffic intensity is no greater than 1.\nNow consider the case La/R ≤ 1. Here, the nature of the arriving traffic impacts\nthe queuing delay. For example, if packets arrive periodically—that is, one packet\narrives every L/R seconds—then every packet will arrive at an empty queue and\nthere will be no queuing delay. On the other hand, if packets arrive in bursts but\nperiodically, there can be a significant average queuing delay. For example, suppose\nN packets arrive simultaneously every (L/R)N seconds. Then the first packet trans-\nmitted has no queuing delay; the second packet transmitted has a queuing delay of\nL/R seconds; and more generally, the n th packet transmitted has a queuing delay of\n( n  1) L/R seconds. We leave it as an exercise for you to calculate the average queu-\ning delay in this example.\nThe two examples of periodic arrivals described above are a bit academic. Typ-\nically, the arrival process to a queue is random; that is, the arrivals do not follow any\npattern and the packets are spaced apart by random amounts of time. In this more\nrealistic case, the quantity La/R is not usually sufficient to fully characterize the\nqueueing delay statistics. Nonetheless, it is useful in gaining an intuitive understand-\ning of the extent of the queuing delay. In particular, if the traffic intensity is close to\nzero, then packet arrivals are few and far between and it is unlikely that an arriving\npacket will find another packet in the queue. Hence, the average queuing delay will\nbe close to zero. On the other hand, when the traffic intensity is close to 1, there will\nbe intervals of time when the arrival rate exceeds the transmission capacity (due to\nvariations in packet arrival rate), and a queue will form during these periods of time;\nwhen the arrival rate is less than the transmission capacity, the length of the queue\nwill shrink. Nonetheless, as the traffic intensity approaches 1, the average queue\nlength gets larger and larger. The qualitative dependence of average queuing delay\nOne important aspect of Figure 1.18 is the fact that as the traffic intensity\napproaches 1, the average queuing delay increases rapidly. A small percentage\nincrease in the intensity will result in a much larger percentage-wise increase in\ndelay. Perhaps you have experienced this phenomenon on the highway. If you regu-\nlarly drive on a road that is typically congested, the fact that the road is typically\ncongested means that its traffic intensity is close to 1. If some event causes an even\nslightly larger-than-usual amount of traffic, the delays you experience can be huge.\nTo really get a good feel for what queuing delays are about, you are encouraged\nonce again to visit the companion Web site, which provides an interactive Java\napplet for a queue. If you set the packet arrival rate high enough so that the traffic\nintensity exceeds 1, you will see the queue slowly build up over time.\nPacket Loss\nIn our discussions above, we have assumed that the queue is capable of holding an\ninfinite number of packets. In reality a queue preceding a link has finite capacity,\nalthough the queuing capacity greatly depends on the router design and cost.\nBecause the queue capacity is finite, packet delays do not really approach infinity as\nthe traffic intensity approaches 1. Instead, a packet can arrive to find a full queue.\nWith no place to store such a packet, a router will drop that packet; that is, the\npacket will be lost . This overflow at a queue can again be seen in the Java applet for\na queue when the traffic intensity is greater than 1.\nFrom an end-system viewpoint, a packet loss will look like a packet having\nbeen transmitted into the network core but never emerging from the network at the\ndestination. The fraction of lost packets increases as the traffic intensity increases.\nTherefore, performance at a node is often measured not only in terms of delay, but\nA v e r a g e\nq u e u i n g\nd e l a y\nLa/R\nchapters, a lost packet may be retransmitted on an end-to-end basis in order to\nensure that all data are eventually transferred from source to destination\n"
  },
  {
    "title": "1.4.3 End-to-End Delay",
    "content": "Our discussion up to this point has focused on the nodal delay, that is, the delay at a\nsingle router. Let’s now consider the total delay from source to destination. To get a\nhandle on this concept, suppose there are N  1 routers between the source host and\nthe destination host. Let’s also suppose for the moment that the network is uncon-\ngested (so that queuing delays are negligible), the processing delay at each router\nand at the source host is d\nproc\n, the transmission rate out of each router and out of the\nsource host is R bits/sec, and the propagation on each link is d\nprop\n. The nodal delays\naccumulate and give an end-to-end delay,\nd\nend-end\n= N ( d\nproc\n+ d\ntrans\n+ d\nprop\n) (1.2)\nwhere, once again, d\ntrans\n= L/R, where L is the packet size. Note that Equation 1.2 is a\ngeneralization of Equation 1.1, which did not take into account processing and propa-\ngation delays. We leave it to you to generalize Equation 1.2 to the case of heteroge-\nneous delays at the nodes and to the presence of an average queuing delay at each node.\nTraceroute\nTo get a hands-on feel for end-to-end delay in a computer network, we can make use\nof the Traceroute program. Traceroute is a simple program that can run in any Inter-\nnet host. When the user specifies a destination hostname, the program in the source\nhost sends multiple, special packets toward that destination. As these packets work\ntheir way toward the destination, they pass through a series of routers. When a\nrouter receives one of these special packets, it sends back to the source a short mes-\nsage that contains the name and address of the router.\nMore specifically, suppose there are N  1 routers between the source and the\ndestination. Then the source will send N special packets into the network, with each\npacket addressed to the ultimate destination. These N special packets are marked 1\nthrough N, with the first packet marked 1 and the last packet marked N . When the n th\nrouter receives the n th packet marked n, the router does not forward the packet\ntoward its destination, but instead sends a message back to the source. When the des-\ntination host receives the N th packet, it too returns a message back to the source. The\nsource records the time that elapses between when it sends a packet and when it\nreceives the corresponding return message; it also records the name and address of\nthe router (or the destination host) that returns the message. In this manner, the source\ncan reconstruct the route taken by packets flowing from source to destination, and\nthe source can determine the round-trip delays to all the intervening routers. Trace-\nroute actually repeats the experiment just described three times, so the source actually\nVideoNote\nUsing Traceroute to\ndiscover network\npaths and measure\nnetwork delay\nHere is an example of the output of the Traceroute program, where the route\nwas being traced from the source host gaia.cs.umass.edu (at the University of Mass-\nachusetts) to the host cis.poly.edu (at Polytechnic University in Brooklyn). The out-\nput has six columns: the first column is the n value described above, that is, the\nnumber of the router along the route; the second column is the name of the router;\nthe third column is the address of the router (of the form xxx.xxx.xxx.xxx); the last\nthree columns are the round-trip delays for three experiments. If the source receives\nfewer than three messages from any given router (due to packet loss in the network),\nTraceroute places an asterisk just after the router number and reports fewer than\nthree round-trip times for that router.\n1 cs-gw (128.119.240.254) 1.009 ms 0.899 ms 0.993 ms\n2 128.119.3.154 (128.119.3.154) 0.931 ms 0.441 ms 0.651 ms\n3 border4-rt-gi-1-3.gw.umass.edu (128.119.2.194) 1.032 ms 0.484 ms 0.451 ms\n4 acr1-ge-2-1-0.Boston.cw.net (208.172.51.129) 10.006 ms 8.150 ms 8.460 ms\n5 agr4-loopback.NewYork.cw.net (206.24.194.104) 12.272 ms 14.344 ms 13.267 ms\n6 acr2-loopback.NewYork.cw.net (206.24.194.62) 13.225 ms 12.292 ms 12.148 ms\n7 pos10-2.core2.NewYork1.Level3.net (209.244.160.133) 12.218 ms 11.823 ms 11.793 ms\n8 gige9-1-52.hsipaccess1.NewYork1.Level3.net (64.159.17.39) 13.081 ms 11.556 ms 13.297 ms\n9 p0-0.polyu.bbnplanet.net (4.25.109.122) 12.716 ms 13.052 ms 12.786 ms\n10 cis.poly.edu (128.238.32.126) 14.080 ms 13.035 ms 12.802 ms\nIn the trace above there are nine routers between the source and the destination.\nMost of these routers have a name, and all of them have addresses. For example, the\nname of Router 3 is border4-rt-gi-1-3.gw.umass.edu and its address is\n128.119.2.194. Looking at the data provided for this same router, we see that\nin the first of the three trials the round-trip delay between the source and the router\nwas 1.03 msec. The round-trip delays for the subsequent two trials were 0.48 and\n0.45 msec. These round-trip delays include all of the delays just discussed, includ-\ning transmission delays, propagation delays, router processing delays, and queuing\ndelays. Because the queuing delay is varying with time, the round-trip delay of\npacket n sent to a router n can sometimes be longer than the round-trip delay of\npacket n+ 1 sent to router n+ 1. Indeed, we observe this phenomenon in the above\nexample: the delays to Router 6 are larger than the delays to Router 7!\nWant to try out Traceroute for yourself? We highly recommended that you visit\nhttp://www.traceroute.org, which provides a Web interface to an extensive list of\nsources for route tracing. You choose a source and supply the hostname for any des-\ntination. The Traceroute program then does all the work. There are a number of free\nsoftware programs that provide a graphical interface to Traceroute; one of our\nfavorites is PingPlotter [PingPlotter 2012].\nEnd System, Application, and Other Delays\nIn addition to processing, transmission, and propagation delays, there can be addi-\ntransmit a packet into a shared medium (e.g., as in a WiFi or cable modem scenario)\nmay purposefully delay its transmission as part of its protocol for sharing the\nmedium with other end systems; we’ll consider such protocols in detail in Chapter\n5. Another important delay is media packetization delay, which is present in Voice-\nover-IP(VoIP) applications. In VoIP, the sending side must first fill a packet with\nencoded digitized speech before passing the packet to the Internet. This time to fill a\npacket—called the packetization delay—can be significant and can impact the user-\nperceived quality of a VoIPcall. This issue will be further explored in a homework\nproblem at the end of this chapter.\n"
  },
  {
    "title": "1.4.4 Throughput in Computer Networks",
    "content": "In addition to delay and packet loss, another critical performance measure in com-\nputer networks is end-to-end throughput. To define throughput, consider transfer-\nring a large file from Host Ato Host B across a computer network. This transfer\nmight be, for example, a large video clip from one peer to another in a P2Pfile\nsharing system. The instantaneous throughput at any instant of time is the rate\n(in bits/sec) at which Host B is receiving the file. (Many applications, including\nmany P2P file sharing systems, display the instantaneous throughput during\ndownloads in the user interface—perhaps you have observed this before!) If the\nfile consists of F bits and the transfer takes T seconds for Host B to receive all F\nbits, then the average throughput of the file transfer is F/T bits/sec. For some\napplications, such as Internet telephony, it is desirable to have a low delay and an\ninstantaneous throughput consistently above some threshold (for example, over\n24 kbps for some Internet telephony applications and over 256 kbps for some real-\ntime video applications). For other applications, including those involving file\ntransfers, delay is not critical, but it is desirable to have the highest possible\nthroughput.\nTo gain further insight into the important concept of throughput, let’s consider a\nfew examples. Figure 1.19(a) shows two end systems, a server and a client, con-\nnected by two communication links and a router. Consider the throughput for a file\ntransfer from the server to the client. Let R\ns\ndenote the rate of the link between\nthe server and the router; and R\nc\ndenote the rate of the link between the router and\nthe client. Suppose that the only bits being sent in the entire network are those\nfrom the server to the client. We now ask, in this ideal scenario, what is the server-\nto-client throughput? To answer this question, we may think of bits as fluid and\ncommunication links as pipes . Clearly, the server cannot pump bits through its link\nat a rate faster than R\ns\nbps; and the router cannot forward bits at a rate faster than R\nc\nbps. If R\ns\n< R\nc\n, then the bits pumped by the server will “flow” right through the\nrouter and arrive at the client at a rate of R\ns\nbps, giving a throughput of R\ns\nbps. If, on\nthe other hand, R\nc\n< R\ns\n, then the router will not be able to forward bits as quickly as\nend-to-end throughput of R\nc\n. (Note also that if bits continue to arrive at the router at\nrate R\ns\n, and continue to leave the router at R\nc\n, the backlog of bits at the router wait-\ning for transmission to the client will grow and grow—a most undesirable situation!)\nThus, for this simple two-link network, the throughput is min{ R\nc\n, R\ns\n}, that is, it is\nthe transmission rate of the bottleneck link . Having determined the throughput, we\ncan now approximate the time it takes to transfer a large file of F bits from server to\nclient as F /min{ R\ns\n, R\nc\n}. For a specific example, suppose you are downloading an\nMP3 file of F = 32 million bits, the server has a transmission rate of R\ns\n= 2 Mbps,\nand you have an access link of R\nc\n= 1 Mbps. The time needed to transfer the file is\nthen 32 seconds. Of course, these expressions for throughput and transfer time are\nonly approximations, as they do not account for store-and-forward and processing\ndelays as well as protocol issues.\nclient, with the transmission rates of the N links being R\n, R\n,..., R\nN\n. Applying the\nsame analysis as for the two-link network, we find that the throughput for a file\ntransfer from server to client is min{ R\n, R\n,..., R\nN\n}, which is once again the trans-\nmission rate of the bottleneck link along the path between server and client.\nNow consider another example motivated by today’s Internet. Figure 1.20(a)\nshows two end systems, a server and a client, connected to a computer network.\nConsider the throughput for a file transfer from the server to the client. The server is\nconnected to the network with an access link of rate R\ns\nand the client is connected to\nthe network with an access link of rate R\nc\n. Now suppose that all the links in the core\nof the communication network have very high transmission rates, much higher than\nR\ns\nand R\nc\n. Indeed, today, the core of the Internet is over-provisioned with high speed\nlinks that experience little congestion. Also suppose that the only bits being sent in\nthe entire network are those from the server to the client. Because the core of the\nServer\nR s\nR 1 R 2 R N\nR c\nClient\nServer\na.\nb.\nClient\nfrom source to destination is again the minimum of R\ns\nand R\nc\n, that is, throughput =\nmin{ R\ns\n, R\nc\n}. Therefore, the constraining factor for throughput in today’s Internet is\ntypically the access network.\nFor a final example, consider Figure 1.20(b) in which there are 10 servers and\n10 clients connected to the core of the computer network. In this example, there are\n10 simultaneous downloads taking place, involving 10 client-server pairs. Suppose\nthat these 10 downloads are the only traffic in the network at the current time. As\nshown in the figure, there is a link in the core that is traversed by all 10 downloads.\nDenote R for the transmission rate of this link R . Let’s suppose that all server access\nlinks have the same rate R\ns\n, all client access links have the same rate R\nc\n, and the\ntransmission rates of all the links in the core—except the one common link of rate\nR— are much larger than R\ns\n, R\nc\n, and R . Now we ask, what are the throughputs of the\ndownloads? Clearly, if the rate of the common link, R , is large—say a hundred times\nlarger than both R\ns\nand R\nc\n—then the throughput for each download will once again\nbe min{ R\ns\n, R\nc\n}. But what if the rate of the common link is of the same order as R\ns\nServer\nR s\nR c\na. b.\nClient 10 Clients\n10 Servers\nBottleneck\nlink of\ncapacityR\nserver; (b) 10 clients downloading with 10 servers\nexample. Suppose R\ns\n= 2 Mbps, R\nc\n= 1 Mbps, R = 5 Mbps, and the common link\ndivides its transmission rate equally among the 10 downloads. Then the bottleneck\nfor each download is no longer in the access network, but is now instead the shared\nlink in the core, which only provides each download with 500 kbps of throughput.\nThus the end-to-end throughput for each download is now reduced to 500 kbps.\nThe examples in Figure 1.19and Figure 1.20(a) show that throughput depends\non the transmission rates of the links over which the data flows. We saw that when\nthere is no other intervening traffic, the throughput can simply be approximated as\nthe minimum transmission rate along the path between source and destination. The\nexample in Figure 1.20(b) shows that more generally the throughput depends not\nonly on the transmission rates of the links along the path, but also on the intervening\ntraffic. In particular, a link with a high transmission rate may nonetheless be the bot-\ntleneck link for a file transfer if many other data flows are also passing through that\nlink. We will examine throughput in computer networks more closely in the home-\nwork problems and in the subsequent chapters.\n"
  },
  {
    "title": "1.5 Protocol Layers and Their Service Models",
    "content": "From our discussion thus far, it is apparent that the Internet is an extremely compli-\ncated system. We have seen that there are many pieces to the Internet: numerous\napplications and protocols, various types of end systems, packet switches, and vari-\nous types of link-level media. Given this enormous complexity, is there any hope of\norganizing a network architecture, or at least our discussion of network architecture?\nFortunately, the answer to both questions is yes.\n"
  },
  {
    "title": "1.5.1 Layered Architecture",
    "content": "Before attempting to organize our thoughts on Internet architecture, let’s look for a\nhuman analogy. Actually, we deal with complex systems all the time in our every-\nday life. Imagine if someone asked you to describe, for example, the airline system.\nHow would you find the structure to describe this complex system that has ticketing\nagents, baggage checkers, gate personnel, pilots, airplanes, air traffic control, and a\nworldwide system for routing airplanes? One way to describe this system might be\nto describe the series of actions you take (or others take for you) when you fly on an\nairline. You purchase your ticket, check your bags, go to the gate, and eventually get\nloaded onto the plane. The plane takes off and is routed to its destination. After your\nplane lands, you deplane at the gate and claim your bags. If the trip was bad, you\ncomplain about the flight to the ticket agent (getting nothing for your effort). This\nscenario is shown in Figure 1.21.\nAlready, we can see some analogies here with computer networking: You are\nsource host to destination host in the Internet. But this is not quite the analogy we\nare after. We are looking for some structure in Figure 1.21. Looking at Figure 1.21,\nwe note that there is a ticketing function at each end; there is also a baggage func-\ntion for already-ticketed passengers, and a gate function for already-ticketed and\nalready-baggage-checked passengers. For passengers who have made it through the\ngate (that is, passengers who are already ticketed, baggage-checked, and through the\ngate), there is a takeoff and landing function, and while in flight, there is an airplane-\nrouting function. This suggests that we can look at the functionality in Figure 1.21\nin a horizontal manner, as shown in Figure 1.22.\nwork in which we can discuss airline travel. Note that each layer, combined with the\nTicket (purchase)\nBaggage (check)\nGates (load)\nRunway takeoff\nAirplane routing Airplane routing Airplane routing\nTicket (complain)\nBaggage (claim)\nGates (unload)\nRunway landing\nAirplane routing\nTicket\nBaggage\nGate\nTakeoff/Landing\nDeparture airport Intermediate air-traffic\ncontrol centers\nTicket (purchase)\nBaggage (check)\nGates (load)\nRunway takeoff\nAirplane routing\nTicket (complain)\nBaggage (claim)\nGates (unload)\nRunway landing\nAirplane routing\nAirplane routing\nlayers below it, implements some functionality, some service. At the ticketing layer\nand below, airline-counter-to-airline-counter transfer of a person is accomplished.\nAt the baggage layer and below, baggage-check-to-baggage-claim transfer of a per-\nson and bags is accomplished. Note that the baggage layer provides this service only\nto an already-ticketed person. At the gate layer, departure-gate-to-arrival-gate trans-\nfer of a person and bags is accomplished. At the takeoff/landing layer, runway-to-\nrunway transfer of people and their bags is accomplished. Each layer provides its\nservice by (1) performing certain actions within that layer (for example, at the gate\nlayer, loading and unloading people from an airplane) and by (2) using the services\nof the layer directly below it (for example, in the gate layer, using the runway-to-\nrunway passenger transfer service of the takeoff/landing layer).\nAlayered architecture allows us to discuss a well-defined, specific part of a\nlarge and complex system. This simplification itself is of considerable value by pro-\nviding modularity, making it much easier to change the implementation of the serv-\nice provided by the layer. As long as the layer provides the same service to the layer\nabove it, and uses the same services from the layer below it, the remainder of the\nsystem remains unchanged when a layer’s implementation is changed. (Note that\nchanging the implementation of a service is very different from changing the serv-\nice itself!) For example, if the gate functions were changed (for instance, to have\npeople board and disembark by height), the remainder of the airline system would\nremain unchanged since the gate layer still provides the same function (loading and\nunloading people); it simply implements that function in a different manner after the\nchange. For large and complex systems that are constantly being updated, the ability\nto change the implementation of a service without affecting other components of the\nsystem is another important advantage of layering.\nProtocol Layering\nBut enough about airlines. Let’s now turn our attention to network protocols. To\nprovide structure to the design of network protocols, network designers organize\nprotocols—and the network hardware and software that implement the protocols—\nin layers . Each protocol belongs to one of the layers, just as each function in the\nairline architecture in Figure 1.22belonged to a layer. We are again interested in\nthe services that a layer offers to the layer above—the so-called service model of\na layer. Just as in the case of our airline example, each layer provides its service\nby (1) performing certain actions within that layer and by (2) using the services of\nthe layer directly below it. For example, the services provided by layer n may\ninclude reliable delivery of messages from one edge of the network to the other.\nThis might be implemented by using an unreliable edge-to-edge message delivery\nservice of layer n  1, and adding layer n functionality to detect and retransmit\nlost messages.\nAprotocol layer can be implemented in software, in hardware, or in a combina-\nalways implemented in software in the end systems; so are transport-layer protocols.\nBecause the physical layer and data link layers are responsible for handling commu-\nnication over a specific link, they are typically implemented in a network interface\ncard (for example, Ethernet or WiFi interface cards) associated with a given link.\nThe network layer is often a mixed implementation of hardware and software. Also\nnote that just as the functions in the layered airline architecture were distributed\namong the various airports and flight control centers that make up the system, so too\nis a layer n protocol distributed among the end systems, packet switches, and other\ncomponents that make up the network. That is, there’s often a piece of a layer n pro-\ntocol in each of these network components.\nProtocol layering has conceptual and structural advantages [RFC 3439]. As we\nhave seen, layering provides a structured way to discuss system components. Mod-\nularity makes it easier to update system components. We mention, however, that\nsome researchers and networking engineers are vehemently opposed to layering\n[Wakeman 1992]. One potential drawback of layering is that one layer may dupli-\ncate lower-layer functionality. For example, many protocol stacks provide error\nrecovery on both a per-link basis and an end-to-end basis. Asecond potential draw-\nback is that functionality at one layer may need information (for example, a time-\nstamp value) that is present only in another layer; this violates the goal of\nseparation of layers.\nWhen taken together, the protocols of the various layers are called the protocol\nstack . The Internet protocol stack consists of five layers: the physical, link, network,\ntransport, and application layers, as shown in Figure 1.23(a). If you examine the\nlayers of the Internet protocol stack. We take a top-down approach , first covering\nTransport\nApplication\nNetwork\nLink\nPhysical\na. Five-layer\nInternet\nprotocol stack\nTransport\nSession\nApplication\nPresentation\nNetwork\nLink\nPhysical\nb. Seven-layer\nISO OSI\nreference model\nApplication Layer\nThe application layer is where network applications and their application-layer proto-\ncols reside. The Internet’s application layer includes many protocols, such as the HTTP\nprotocol (which provides for Web document request and transfer), SMTP(which pro-\nvides for the transfer of e-mail messages), and FTP(which provides for the transfer of\nfiles between two end systems). We’ll see that certain network functions, such as the\ntranslation of human-friendly names for Internet end systems like www.ietf.orgto a\n32-bit network address, are also done with the help of a specific application-layer pro-\ntocol, namely, the domain name system (DNS). We’ll see in Chapter 2that it is very\neasy to create and deploy our own new application-layer protocols.\nAn application-layer protocol is distributed over multiple end systems, with the\napplication in one end system using the protocol to exchange packets of information\nwith the application in another end system. We’ll refer to this packet of information\nat the application layer as a message .\nTransport Layer\nThe Internet’s transport layer transports application-layer messages between\napplication endpoints. In the Internet there are two transport protocols, TCPand\nUDP, either of which can transport application-layer messages. TCPprovides a\nconnection-oriented service to its applications. This service includes guaranteed\ndelivery of application-layer messages to the destination and flow control (that is,\nsender/receiver speed matching). TCPalso breaks long messages into shorter seg-\nments and provides a congestion-control mechanism, so that a source throttles its\ntransmission rate when the network is congested. The UDPprotocol provides a con-\nnectionless service to its applications. This is a no-frills service that provides no\nreliability, no flow control, and no congestion control. In this book, we’ll refer to a\ntransport-layer packet as a segment .\nNetwork Layer\nThe Internet’s network layer is responsible for moving network-layer packets\nknown as datagrams from one host to another. The Internet transport-layer proto-\ncol (TCPor UDP) in a source host passes a transport-layer segment and a destina-\ntion address to the network layer, just as you would give the postal service a letter\nwith a destination address. The network layer then provides the service of deliver-\ning the segment to the transport layer in the destination host.\nThe Internet’s network layer includes the celebrated IPProtocol, which defines\nthe fields in the datagram as well as how the end systems and routers act on these\nfields. There is only one IPprotocol, and all Internet components that have a net-\nwork layer must run the IPprotocol. The Internet’s network layer also contains rout-\ndestinations. The Internet has many routing protocols. As we saw in Section 1.3, the\nInternet is a network of networks, and within a network, the network administrator\ncan run any routing protocol desired. Although the network layer contains both the\nIPprotocol and numerous routing protocols, it is often simply referred to as the IP\nlayer, reflecting the fact that IPis the glue that binds the Internet together.\nLink Layer\nThe Internet’s network layer routes a datagram through a series of routers between\nthe source and destination. To move a packet from one node (host or router) to the\nnext node in the route, the network layer relies on the services of the link layer. In\nparticular, at each node, the network layer passes the datagram down to the link\nlayer, which delivers the datagram to the next node along the route. At this next\nnode, the link layer passes the datagram up to the network layer.\nThe services provided by the link layer depend on the specific link-layer proto-\ncol that is employed over the link. For example, some link-layer protocols provide\nreliable delivery, from transmitting node, over one link, to receiving node. Note that\nthis reliable delivery service is different from the reliable delivery service of TCP,\nwhich provides reliable delivery from one end system to another. Examples of link-\nlayer protocols include Ethernet, WiFi, and the cable access network’s DOCSIS pro-\ntocol. As datagrams typically need to traverse several links to travel from source to\ndestination, a datagram may be handled by different link-layer protocols at different\nlinks along its route. For example, a datagram may be handled by Ethernet on one\nlink and by PPPon the next link. The network layer will receive a different service\nfrom each of the different link-layer protocols. In this book, we’ll refer to the link-\nlayer packets as frames .\nPhysical Layer\nWhile the job of the link layer is to move entire frames from one network element\nto an adjacent network element, the job of the physical layer is to move the individ-\nual bits within the frame from one node to the next. The protocols in this layer are\nagain link dependent and further depend on the actual transmission medium of the\nlink (for example, twisted-pair copper wire, single-mode fiber optics). For example,\nEthernet has many physical-layer protocols: one for twisted-pair copper wire,\nanother for coaxial cable, another for fiber, and so on. In each case, a bit is moved\nacross the link in a different way.\nThe OSI Model\nHaving discussed the Internet protocol stack in detail, we should mention that it is\nnot the only protocol stack around. In particular, back in the late 1970s, the Interna-\norganized around seven layers, called the Open Systems Interconnection (OSI)\nmodel [ISO 2012]. The OSI model took shape when the protocols that were to\nbecome the Internet protocols were in their infancy, and were but one of many dif-\nferent protocol suites under development; in fact, the inventors of the original OSI\nmodel probably did not have the Internet in mind when creating it. Nevertheless,\nbeginning in the late 1970s, many training and university courses picked up on the\nISO mandate and organized courses around the seven-layer model. Because of its\nearly impact on networking education, the seven-layer model continues to linger on\nin some networking textbooks and training courses.\nThe seven layers of the OSI reference model, shown in Figure 1.23(b), are:\napplication layer, presentation layer, session layer, transport layer, network layer,\ndata link layer, and physical layer. The functionality of five of these layers is\nroughly the same as their similarly named Internet counterparts. Thus, let’s consider\nthe two additional layers present in the OSI reference model—the presentation layer\nand the session layer. The role of the presentation layer is to provide services that\nallow communicating applications to interpret the meaning of data exchanged.\nThese services include data compression and data encryption (which are self-\nexplanatory) as well as data description (which, as we will see in Chapter 9, frees\nthe applications from having to worry about the internal format in which data are\nrepresented/stored—formats that may differ from one computer to another). The\nsession layer provides for delimiting and synchronization of data exchange, includ-\ning the means to build a checkpointing and recovery scheme.\nThe fact that the Internet lacks two layers found in the OSI reference model\nposes a couple of interesting questions: Are the services provided by these layers\nunimportant? What if an application needs one of these services? The Internet’s\nanswer to both of these questions is the same—it’s up to the application developer.\nIt’s up to the application developer to decide if a service is important, and if the\nservice is important, it’s up to the application developer to build that functionality\ninto the application.\n"
  },
  {
    "title": "1.5.2 Encapsulation",
    "content": "protocol stack, up and down the protocol stacks of an intervening link-layer switch\nand router, and then up the protocol stack at the receiving end system. As we discuss\nlater in this book, routers and link-layer switches are both packet switches. Similar\nto end systems, routers and link-layer switches organize their networking hardware\nand software into layers. But routers and link-layer switches do not implement all of\nthe layers in the protocol stack; they typically implement only the bottom layers. As\nshown in Figure 1.24, link-layer switches implement layers 1 and 2; routers imple-\nment layers 1 through 3. This means, for example, that Internet routers are capable\nof implementing the IPprotocol (a layer 3 protocol), while link-layer switches are\nare capable of recognizing layer 2 addresses, such as Ethernet addresses. Note that\nhosts implement all five layers; this is consistent with the view that the Internet\narchitecture puts much of its complexity at the edges of the network.\nsending host, an application-layermessage (M in Figure 1.24) is passed to the\ntransport layer. In the simplest case, the transport layer takes the message and\nappends additional information (so-called transport-layer header information, H\nt\nin Figure 1.24) that will be used by the receiver-side transport layer. The applica-\ntion-layer message and the transport-layer header information together constitute\nthe transport-layersegment . The transport-layer segment thus encapsulates the\napplication-layer message. The added information might include information\nallowing the receiver-side transport layer to deliver the message up to the appro-\npriate application, and error-detection bits that allow the receiver to determine\nwhether bits in the message have been changed in route. The transport layer then\npasses the segment to the network layer, which adds network-layer header infor-\nmation (H\nn\nin Figure 1.24) such as source and destination end system addresses,\nM\nM\nM\nM\nH t\nH t\nH t\nH n\nH n H l\nH t H n H l\nLink-layer switch\nRouter\nApplication\nTransport\nNetwork\nLink\nPhysical\nMessage\nSegment\nDatagram\nFrame\nM\nM\nM\nM\nH t\nH t\nH t\nH n\nH n H l\nLink\nPhysical\nSource\nNetwork\nLink\nPhysical\nDestination\nApplication\nTransport\nNetwork\nLink\nPhysical\nM H t H n H l M\nH t H n M H t H n M\nH t H n H l M H t H n H l M\ndifferent set of layers, reflecting their differences in\nfunctionality\ncreating a network-layer datagram . The datagram is then passed to the link\nlayer, which (of course!) will add its own link-layer header information and create\na link-layer frame . Thus, we see that at each layer, a packet has two types of\nfields: header fields and a payload field . The payload is typically a packet from\nthe layer above.\nAuseful analogy here is the sending of an interoffice memo from one corpo-\nrate branch office to another via the public postal service. Suppose Alice, who is\nin one branch office, wants to send a memo to Bob, who is in another branch\noffice. The memo is analogous to the application-layer message . Alice puts the\nmemo in an interoffice envelope with Bob’s name and department written on the\nfront of the envelope. The interoffice envelope is analogous to a transport-layer\nsegment —it contains header information (Bob’s name and department number)\nand it encapsulates the application-layer message (the memo). When the sending\nbranch-office mailroom receives the interoffice envelope, it puts the interoffice\nenvelope inside yet another envelope, which is suitable for sending through the\npublic postal service. The sending mailroom also writes the postal address of the\nsending and receiving branch offices on the postal envelope. Here, the postal\nenvelope is analogous to the datagram —it encapsulates the transport-layer seg-\nment (the interoffice envelope), which encapsulates the original message (the\nmemo). The postal service delivers the postal envelope to the receiving branch-\noffice mailroom. There, the process of de-encapsulation is begun. The mailroom\nextracts the interoffice memo and forwards it to Bob. Finally, Bob opens the enve-\nlope and removes the memo.\nThe process of encapsulation can be more complex than that described above.\nFor example, a large message may be divided into multiple transport-layer segments\n(which might themselves each be divided into multiple network-layer datagrams).\nAt the receiving end, such a segment must then be reconstructed from its constituent\ndatagrams.\n"
  },
  {
    "title": "1.6 Networks Under Attack",
    "content": "The Internet has become mission critical for many institutions today, including large\nand small companies, universities, and government agencies. Many individuals also\nrely on the Internet for many of their professional, social, and personal activities.\nBut behind all this utility and excitement, there is a dark side, a side where “bad\nguys” attempt to wreak havoc in our daily lives by damaging our Internet-connected\ncomputers, violating our privacy, and rendering inoperable the Internet services on\nwhich we depend.\nThe field of network security is about how the bad guys can attack computer\nnetworks and about how we, soon-to-be experts in computer networking, can\ndefend networks against those attacks, or better yet, design new architectures that\nare immune to such attacks in the first place. Given the frequency and variety of\nexisting attacks as well as the threat of new and more destructive future attacks,\nnetwork security has become a central topic in the field of computer networking.\nOne of the features of this textbook is that it brings network security issues to the\nforefront.\nSince we don’t yet have expertise in computer networking and Internet proto-\ncols, we’ll begin here by surveying some of today’s more prevalent security-\nrelated problems. This will whet our appetite for more substantial discussions in\nthe upcoming chapters. So we begin here by simply asking, what can go wrong?\nHow are computer networks vulnerable? What are some of the more prevalent\ntypes of attacks today?\nThe bad guys can put malware into your host via the Internet\nWe attach devices to the Internet because we want to receive/send data from/to\nthe Internet. This includes all kinds of good stuff, including Web pages, e-mail\nmessages, MP3s, telephone calls, live video, search engine results, and so on.\nBut, unfortunately, along with all that good stuff comes malicious stuff—collec-\ntively known as malware —that can also enter and infect our devices. Once mal-\nware infects our device it can do all kinds of devious things, including deleting\nour files; installing spyware that collects our private information, such as social\nsecurity numbers, passwords, and keystrokes, and then sends this (over the Inter-\nnet, of course!) back to the bad guys. Our compromised host may also be\nenrolled in a network of thousands of similarly compromised devices, collec-\ntively known as a botnet , which the bad guys control and leverage for spam e-\nmail distribution or distributed denial-of-service attacks (soon to be discussed)\nagainst targeted hosts.\nMuch of the malware out there today is self-replicating : once it infects one\nhost, from that host it seeks entry into other hosts over the Internet, and from the\nnewly infected hosts, it seeks entry into yet more hosts. In this manner, self-\nreplicating malware can spread exponentially fast. Malware can spread in the\nform of a virus or a worm. Viruses are malware that require some form of user\ninteraction to infect the user’s device. The classic example is an e-mail attachment\ncontaining malicious executable code. If a user receives and opens such an attach-\nment, the user inadvertently runs the malware on the device. Typically, such e-\nmail viruses are self-replicating: once executed, the virus may send an identical\nmessage with an identical malicious attachment to, for example, every recipient in\nthe user’s address book. Worms are malware that can enter a device without any\nexplicit user interaction. For example, a user may be running a vulnerable network\napplication to which an attacker can send malware. In some cases, without any\nuser intervention, the application may accept the malware from the Internet and\nrun it, creating a worm. The worm in the newly infected device then scans the\nInternet, searching for other hosts running the same vulnerable network applica-\ntion. When it finds other vulnerable hosts, it sends a copy of itself to those hosts.\nToday, malware, is pervasive and costly to defend against. As you work through\nthis textbook, we encourage you to think about the following question: What can\ncomputer network designers do to defend Internet-attached devices from malware\nattacks?\nThe bad guys can attack servers and network infrastructure\nAnother broad class of security threats are known as denial-of-service (DoS)\nattacks . As the name suggests, a DoS attack renders a network, host, or other piece\nof infrastructure unusable by legitimate users. Web servers, e-mail servers, DNS\nservers (discussed in Chapter 2), and institutional networks can all be subject to DoS\nattacks. Internet DoS attacks are extremely common, with thousands of DoS attacks\noccurring every year [Moore 2001; Mirkovic 2005]. Most Internet DoS attacks fall\ninto one of three categories:\n• Vulnerability attack. This involves sending a few well-crafted messages to a vul-\nnerable application or operating system running on a targeted host. If the right\nsequence of packets is sent to a vulnerable application or operating system, the\nservice can stop or, worse, the host can crash.\n• Bandwidth flooding. The attacker sends a deluge of packets to the targeted\nhost—so many packets that the target’s access link becomes clogged, preventing\nlegitimate packets from reaching the server.\n• Connection flooding. The attacker establishes a large number of half-open or\nfully open TCPconnections (TCPconnections are discussed in Chapter 3) at the\ntarget host. The host can become so bogged down with these bogus connections\nthat it stops accepting legitimate connections.\nLet’s now explore the bandwidth-flooding attack in more detail. Recalling our\ndelay and loss analysis discussion in Section 1.4.2, it’s evident that if the server has an\naccess rate of R bps, then the attacker will need to send traffic at a rate of approxi-\nmately R bps to cause damage. If R is very large, a single attack source may not be\nable to generate enough traffic to harm the server. Furthermore, if all the traffic\nemanates from a single source, an upstream router may be able to detect the attack and\nblock all traffic from that source before the traffic gets near the server. In a distributed\nDoS (DDoS) attack, illustrated in Figure 1.25, the attacker controls multiple sources\nand has each source blast traffic at the target. With this approach, the aggregate traffic\nrate across all the controlled sources needs to be approximately R to cripple the\nservice. DDoS attacks leveraging botnets with thousands of comprised hosts are a\ncommon occurrence today [Mirkovic 2005]. DDos attacks are much harder to detect\nand defend against than a DoS attack from a single host.\nWe encourage you to consider the following question as you work your way\nthrough this book: What can computer network designers do to defend against DoS\nattacks? We will see that different defenses are needed for the three types of DoS\nattacks.\nThe bad guys can sniff packets\nMany users today access the Internet via wireless devices, such as WiFi-connected\nlaptops or handheld devices with cellular Internet connections (covered in Chapter\n6). While ubiquitous Internet access is extremely convenient and enables marvelous\nnew applications for mobile users, it also creates a major security vulnerability—by\nplacing a passive receiver in the vicinity of the wireless transmitter, that receiver can\nobtain a copy of every packet that is transmitted! These packets can contain all kinds\nof sensitive information, including passwords, social security numbers, trade\nsecrets, and private personal messages. Apassive receiver that records a copy of\nevery packet that flies by is called a packet sniffer .\nSniffers can be deployed in wired environments as well. In wired broadcast envi-\nronments, as in many Ethernet LANs, a packet sniffer can obtain copies of broadcast\npackets sent over the LAN. As described in Section 1.2, cable access technologies\nalso broadcast packets and are thus vulnerable to sniffing. Furthermore, a bad guy\nAttacker\n“start\nattack”\nSlave\nSlave\nSlave\nVictim\nSlave\nSlave\nbe able to plant a sniffer that makes a copy of every packet going to/from the organi-\nzation. Sniffed packets can then be analyzed offline for sensitive information.\nPacket-sniffing software is freely available at various Web sites and as commercial\nproducts. Professors teaching a networking course have been known to assign lab exer-\ncises that involve writing a packet-sniffing and application-layer data reconstruction\nprogram. Indeed, the Wireshark [Wireshark 2012] labs associated with this text (see the\nintroductory Wireshark lab at the end of this chapter) use exactly such a packet sniffer!\nBecause packet sniffers are passive—that is, they do not inject packets into the\nchannel—they are difficult to detect. So, when we send packets into a wireless chan-\nnel, we must accept the possibility that some bad guy may be recording copies of\nour packets. As you may have guessed, some of the best defenses against packet\nsniffing involve cryptography. We will examine cryptography as it applies to net-\nwork security in Chapter 8.\nThe bad guys can masquerade as someone you trust\nIt is surprisingly easy ( you will have the knowledge to do so shortly as you proceed\nthrough this text!) to create a packet with an arbitrary source address, packet con-\ntent, and destination address and then transmit this hand-crafted packet into the\nInternet, which will dutifully forward the packet to its destination. Imagine the\nunsuspecting receiver (say an Internet router) who receives such a packet, takes the\n(false) source address as being truthful, and then performs some command embed-\nded in the packet’s contents (say modifies its forwarding table). The ability to inject\npackets into the Internet with a false source address is known as IPspoofing , and is\nbut one of many ways in which one user can masquerade as another user.\nTo solve this problem, we will need end-point authentication, that is, a mecha-\nnism that will allow us to determine with certainty if a message originates from\nwhere we think it does. Once again, we encourage you to think about how this can\nbe done for network applications and protocols as you progress through the chapters\nof this book. We will explore mechanisms for end-point authentication in Chapter 8.\nIn closing this section, it’s worth considering how the Internet got to be such an\ninsecure place in the first place. The answer, in essence, is that the Internet was orig-\ninally designed to be that way, based on the model of “a group of mutually trusting\nusers attached to a transparent network” [Blumenthal 2001]—a model in which (by\ndefinition) there is no need for security. Many aspects of the original Internet archi-\ntecture deeply reflect this notion of mutual trust. For example, the ability for one\nuser to send a packet to any other user is the default rather than a requested/granted\ncapability, and user identity is taken at declared face value, rather than being authen-\nticated by default.\nBut today’s Internet certainly does not involve “mutually trusting users.”\nNonetheless, today’s users still need to communicate when they don’t necessarily\ntrust each other, may wish to communicate anonymously, may communicate indi-\nmobility-assisting agents, which we’ll study in Chapter 6), and may distrust the\nhardware, software, and even the air through which they communicate. We now\nhave many security-related challenges before us as we progress through this book:\nWe should seek defenses against sniffing, end-point masquerading, man-in-the-\nmiddle attacks, DDoS attacks, malware, and more. We should keep in mind that\ncommunication among mutually trusted users is the exception rather than the rule.\nWelcome to the world of modern computer networking!\n"
  },
  {
    "title": "1.7 History of Computer Networking and",
    "content": "the Internet\nSections 1.1 through 1.6 presented an overview of the technology of computer net-\nworking and the Internet. You should know enough now to impress your family and\nfriends! However, if you really want to be a big hit at the next cocktail party, you\nshould sprinkle your discourse with tidbits about the fascinating history of the Inter-\nnet [Segaller 1998].\n"
  },
  {
    "title": "1.7.1 The Development of Packet Switching: 1961–1972",
    "content": "The field of computer networking and today’s Internet trace their beginnings\nback to the early 1960s, when the telephone network was the world’s dominant\ncommunication network. Recall from Section 1.3 that the telephone network uses\ncircuit switching to transmit information from a sender to a receiver—an appro-\npriate choice given that voice is transmitted at a constant rate between sender\nand receiver. Given the increasing importance of computers in the early 1960s\nand the advent of timeshared computers, it was perhaps natural to consider how\nto hook computers together so that they could be shared among geographically\ndistributed users. The traffic generated by such users was likely to be bursty —\nintervals of activity, such as the sending of a command to a remote computer, fol-\nlowed by periods of inactivity while waiting for a reply or while contemplating\nthe received response.\nThree research groups around the world, each unaware of the others’work\n[Leiner 1998], began inventing packet switching as an efficient and robust alterna-\ntive to circuit switching. The first published work on packet-switching techniques\nwas that of Leonard Kleinrock [Kleinrock 1961; Kleinrock 1964], then a graduate\nstudent at MIT. Using queuing theory, Kleinrock’s work elegantly demonstrated the\neffectiveness of the packet-switching approach for bursty traffic sources. In 1964,\nPaul Baran [Baran 1964] at the Rand Institute had begun investigating the use of\npacket switching for secure voice over military networks, and at the National Physi-\ncal Laboratory in England, Donald Davies and Roger Scantlebury were also devel-\nThe work at MIT, Rand, and the NPLlaid the foundations for today’s Inter-\nnet. But the Internet also has a long history of a let’s-build-it-and-demonstrate-it\nattitude that also dates back to the 1960s. J. C. R. Licklider [DEC 1990] and\nLawrence Roberts, both colleagues of Kleinrock’s at MIT, went on to lead the\ncomputer science program at the Advanced Research Projects Agency (ARPA) in\nthe United States. Roberts published an overall plan for the ARPAnet [Roberts\n1967], the first packet-switched computer network and a direct ancestor of today’s\npublic Internet. On Labor Day in 1969, the first packet switch was installed at\nUCLAunder Kleinrock’s supervision, and three additional packet switches were\ninstalled shortly thereafter at the Stanford Research Institute (SRI), UC Santa Bar-\nbara, and the University of Utah (Figure 1.26). The fledgling precursor to the\nInternet was four nodes large by the end of 1969. Kleinrock recalls the very first\nuse of the network to perform a remote login from UCLAto SRI, crashing the sys-\ntem [Kleinrock 2004].\nBy 1972, ARPAnet had grown to approximately 15 nodes and was given its first\npublic demonstration by Robert Kahn. The first host-to-host protocol between\nARPAnet end systems, known as the network-control protocol (NCP), was com-\npleted [RFC 001]. With an end-to-end protocol available, applications could now be\nwritten. Ray Tomlinson wrote the first e-mail program in 1972.\n"
  },
  {
    "title": "1.7.2 Proprietary Networks and Internetworking: 1972–1980",
    "content": "The initial ARPAnet was a single, closed network. In order to communicate with an\nARPAnet host, one had to be actually attached to another ARPAnet IMP. In the early\nto mid-1970s, additional stand-alone packet-switching networks besides ARPAnet\ncame into being: ALOHANet, a microwave network linking universities on the\nHawaiian islands [Abramson 1970], as well as DARPA’s packet-satellite [RFC 829]\nand packet-radio networks [Kahn 1978]; Telenet, a BBN commercial packet-\nswitching network based on ARPAnet technology; Cyclades, a French packet-\nswitching network pioneered by Louis Pouzin [Think 2012]; Time-sharing networks\nsuch as Tymnet and the GE Information Services network, among others, in the late\n1960s and early 1970s [Schwartz 1977]; IBM’s SNA(1969–1974), which paral-\nleled the ARPAnet work [Schwartz 1977].\nThe number of networks was growing. With perfect hindsight we can see that\nthe time was ripe for developing an encompassing architecture for connecting net-\nworks together. Pioneering work on interconnecting networks (under the sponsor-\nship of the Defense Advanced Research Projects Agency (DARPA)), in essence\ncreating a network of networks, was done by Vinton Cerf and Robert Kahn [Cerf\n1974]; the term internetting was coined to describe this work.\nThese architectural principles were embodied in TCP. The early versions of\nTCP, however, were quite different from today’s TCP. The early versions of TCP\ncombined a reliable in-sequence delivery of data via end-system retransmission\n(still part of today’s TCP) with forwarding functions (which today are performed\nby IP). Early experimentation with TCP, combined with the recognition of the\nimportance of an unreliable, non-flow-controlled, end-to-end transport service\nfor applications such as packetized voice, led to the separation of IPout of TCP\nand the development of the UDPprotocol. The three key Internet protocols that\nwe see today—TCP, UDP, and IP—were conceptually in place by the end of the\n1970s.\nIn addition to the DARPAInternet-related research, many other important\nnetworking activities were underway. In Hawaii, Norman Abramson was devel-\noping ALOHAnet, a packet-based radio network that allowed multiple remote\nsites on the Hawaiian Islands to communicate with each other. The ALOHAprotocol\n[Abramson 1970] was the first multiple-access protocol, allowing geographically\ndistributed users to share a single broadcast communication medium (a radio fre-\nquency). Metcalfe and Boggs built on Abramson’s multiple-access protocol work\nwhen they developed the Ethernet protocol [Metcalfe 1976] for wire-based\nshared broadcast networks.Interestingly, Metcalfe and Boggs’Ethernet protocol\nwas motivated by the need to connect multiple PCs, printers, and shared disks\n[Perkins 1994]. Twenty-five years ago, well before the PC revolution and the\nexplosion of networks, Metcalfe and Boggs were laying the foundation for\ntoday’s PC LANs.\n"
  },
  {
    "title": "1.7.3 A Proliferation of Networks: 1980–1990",
    "content": "By the end of the 1970s, approximately two hundred hosts were connected to the\nARPAnet. By the end of the 1980s the number of hosts connected to the public\nInternet, a confederation of networks looking much like today’s Internet, would\nreach a hundred thousand. The 1980s would be a time of tremendous growth.\nMuch of that growth resulted from several distinct efforts to create computer\nnetworks linking universities together. BITNETprovided e-mail and file transfers\namong several universities in the Northeast. CSNET(computer science network)\nwas formed to link university researchers who did not have access to ARPAnet. In\n1986, NSFNETwas created to provide access to NSF-sponsored supercomputing\ncenters. Starting with an initial backbone speed of 56 kbps, NSFNET’s backbone\nwould be running at 1.5 Mbps by the end of the decade and would serve as a pri-\nmary backbone linking regional networks.\nIn the ARPAnet community, many of the final pieces of today’s Internet archi-\ntecture were falling into place. January 1, 1983 saw the official deployment of\nTCP/IPas the new standard host protocol for ARPAnet (replacing the NCPproto-\ncol). The transition [RFC 801] from NCP to TCP/IP was a flag day event—all\nhosts were required to transfer over to TCP/IPas of that day. In the late 1980s,\nimportant extensions were made to TCPto implement host-based congestion con-\ntrol [Jacobson 1988]. The DNS, used to map between a human-readable Internet\nname (for example, gaia.cs.umass.edu) and its 32-bit IPaddress, was also devel-\noped [RFC 1034].\nParalleling this development of the ARPAnet (which was for the most part a\nUS effort), in the early 1980s the French launched the Minitel project, an ambi-\ntious plan to bring data networking into everyone’s home. Sponsored by the\nFrench government, the Minitel system consisted of a public packet-switched net-\nwork (based on the X.25 protocol suite), Minitel servers, and inexpensive termi-\nnals with built-in low-speed modems. The Minitel became a huge success in 1984\nwhen the French government gave away a free Minitel terminal to each French\nhousehold that wanted one. Minitel sites included free sites—such as a telephone\ndirectory site—as well as private sites, which collected a usage-based fee from\neach user. At its peak in the mid 1990s, it offered more than 20,000 services, rang-\ning from home banking to specialized research databases. The Minitel was in a\nlarge proportion of French homes 10 years before most Americans had ever heard\nof the Internet.\n"
  },
  {
    "title": "1.7.4 The Internet Explosion: The 1990s",
    "content": "The 1990s were ushered in with a number of events that symbolized the continued\nevolution and the soon-to-arrive commercialization of the Internet. ARPAnet, the\nprogenitor of the Internet, ceased to exist. In 1991, NSFNETlifted its restrictions on\nthe use of NSFNETfor commercial purposes. NSFNETitself would be decommis-\nsioned in 1995, with Internet backbone traffic being carried by commercial Internet\nService Providers.\nThe main event of the 1990s was to be the emergence of the World Wide Web\napplication, which brought the Internet into the homes and businesses of millions of\npeople worldwide. The Web served as a platform for enabling and deploying hun-\ndreds of new applications that we take for granted today, including search (e.g.,\nGoogle and Bing) Internet commerce (e.g., Amazon and eBay) and social networks\n(e.g., Facebook).\nThe Web was invented at CERN by Tim Berners-Lee between 1989 and 1991\n[Berners-Lee 1989], based on ideas originating in earlier work on hypertext from\nthe 1940s by Vannevar Bush [Bush 1945] and since the 1960s by Ted Nelson\n[Xanadu 2012]. Berners-Lee and his associates developed initial versions of HTML,\nHTTP, a Web server, and a browser—the four key components of the Web. Around\nthe end of 1993 there were about two hundred Web servers in operation, this collec-\ntion of servers being just a harbinger of what was about to come. At about this time\nseveral researchers were developing Web browsers with GUI interfaces, including\nMarc Andreessen, who along with Jim Clark, formed Mosaic Communications,\nwhich later became Netscape Communications Corporation [Cusumano 1998; Quittner\n1998]. By 1995, university students were using Netscape browsers to surf the Web\non a daily basis. At about this time companies—big and small—began to operate\nWeb servers and transact commerce over the Web. In 1996, Microsoft started to\nmake browsers, which started the browser war between Netscape and Microsoft,\nwhich Microsoft won a few years later [Cusumano 1998].\nThe second half of the 1990s was a period of tremendous growth and innova-\ntion for the Internet, with major corporations and thousands of startups creating\nInternet products and services. By the end of the millennium the Internet was sup-\nporting hundreds of popular applications, including four killer applications:\n• E-mail, including attachments and Web-accessible e-mail\n• The Web, including Web browsing and Internet commerce\n• Instant messaging, with contact lists\n• Peer-to-peer file sharing of MP3s, pioneered by Napster\nInterestingly, the first two killer applications came from the research community,\nwhereas the last two were created by a few young entrepreneurs.\nThe period from 1995 to 2001 was a roller-coaster ride for the Internet in the\nfinancial markets. Before they were even profitable, hundreds of Internet startups\nmade initial public offerings and started to be traded in a stock market. Many com-\npanies were valued in the billions of dollars without having any significant revenue\nstreams. The Internet stocks collapsed in 2000–2001, and many startups shut down.\nNevertheless, a number of companies emerged as big winners in the Internet space,\nincluding Microsoft, Cisco, Yahoo, e-Bay, Google, and Amazon.\n"
  },
  {
    "title": "1.7.5 The New Millennium",
    "content": "Innovation in computer networking continues at a rapid pace. Advances are being\nmade on all fronts, including deployments of faster routers and higher transmission\nspeeds in both access networks and in network backbones. But the following devel-\nopments merit special attention:\n• Since the beginning of the millennium, we have been seeing aggressive deploy-\nment of broadband Internet access to homes—not only cable modems and DSL\nbut also fiber to the home, as discussed in Section 1.2. This high-speed Internet\naccess has set the stage for a wealth of video applications, including the distribu-\ntion of user-generated video (for example, YouTube), on-demand streaming of\nmovies and television shows (e.g., Netflix) , and multi-person video conference\n(e.g., Skype).\n• The increasing ubiquity of high-speed (54 Mbps and higher) public WiFi net-\nworks and medium-speed (up to a few Mbps) Internet access via 3G and 4G\ncellular telephony networks is not only making it possible to remain con-\nstantly connected while on the move, but also enabling new location-specific\napplications. The number of wireless devices connecting to the Internet sur-\npassed the number of wired devices in 2011. This high-speed wireless access\nhas set the stage for the rapid emergence of hand-held computers (iPhones,\nAndroids, iPads, and so on), which enjoy constant and untethered access to\nthe Internet.\n• Online social networks, such as Facebook and Twitter, have created massive peo-\nple networks on top of the Internet. Many Internet users today “live” primarily\nwithin Facebook. Through their APIs, the online social networks create plat-\nforms for new networked applications and distributed games.\n• As discussed in Section 1.3.3, online service providers, such as Google and\nMicrosoft, have deployed their own extensive private networks, which not only\nconnect together their globally distributed data centers, but are used to bypass\nthe Internet as much as possible by peering directly with lower-tier ISPs. As a\nresult, Google provides search results and email access almost instantaneously,\nas if their data centers were running within one’s own computer.\n• Many Internet commerce companies are now running their applications in the\n“cloud”—such as in Amazon’s EC2, in Google’s Application Engine, or in\nMicrosoft’s Azure. Many companies and universities have also migrated their Inter-\nnet applications (e.g., email and Web hosting) to the cloud. Cloud companies not\nonly provide applications scalable computing and storage environments, but also\nprovide the applications implicit access to their high-performance private networks.\n"
  },
  {
    "title": "1.8 Summary",
    "content": "In this chapter we’ve covered a tremendous amount of material! We’ve looked at the\nvarious pieces of hardware and software that make up the Internet in particular and\ncomputer networks in general. We started at the edge of the network, looking at end\nsystems and applications, and at the transport service provided to the applications\nrunning on the end systems. We also looked at the link-layer technologies and phys-\nical media typically found in the access network. We then dove deeper inside the\nnetwork, into the network core, identifying packet switching and circuit switching\nas the two basic approaches for transporting data through a telecommunication net-\nwork, and we examined the strengths and weaknesses of each approach. We also\nexamined the structure of the global Internet, learning that the Internet is a network\nof networks. We saw that the Internet’s hierarchical structure, consisting of higher-\nand lower-tier ISPs, has allowed it to scale to include thousands of networks.\nIn the second part of this introductory chapter, we examined several topics central\nto the field of computer networking. We first examined the causes of delay, through-\nput and packet loss in a packet-switched network. We developed simple quantitative\nmodels for transmission, propagation, and queuing delays as well as for throughput;\nwe’ll make extensive use of these delay models in the homework problems through-\nout this book. Next we examined protocol layering and service models, key architec-\ntural principles in networking that we will also refer back to throughout this book. We\nalso surveyed some of the more prevalent security attacks in the Internet day. We fin-\nished our introduction to networking with a brief history of computer networking. The\nfirst chapter in itself constitutes a mini-course in computer networking.\nSo, we have indeed covered a tremendous amount of ground in this first chapter!\nIf you’re a bit overwhelmed, don’t worry. In the following chapters we’ll revisit all of\nthese ideas, covering them in much more detail (that’s a promise, not a threat!). At this\nthat make up a network, a still-developing command of the vocabulary of networking\n(don’t be shy about referring back to this chapter), and an ever-growing desire to learn\nmore about networking. That’s the task ahead of us for the rest of this book.\nRoad-Mapping This Book\nBefore starting any trip, you should always glance at a road map in order to become\nfamiliar with the major roads and junctures that lie ahead. For the trip we are about\nto embark on, the ultimate destination is a deep understanding of the how, what, and\nwhy of computer networks. Our road map is the sequence of chapters of this book:\n1. Computer Networks and the Internet\n2. Application Layer\n3. Transport Layer\n4. Network Layer\n5. Link Layer and Local Area Networks\n6. Wireless and Mobile Networks\n7. Multimedia Networking\n8. Security in Computer Networks\n9. Network Management\nChapters 2through 5are the four core chapters of this book. You should notice\nthat these chapters are organized around the top four layers of the five-layer Internet\nprotocol stack, one chapter for each layer. Further note that our journey will begin at\nthe top of the Internet protocol stack, namely, the application layer, and will work\nits way downward. The rationale behind this top-down journey is that once we\nunderstand the applications, we can understand the network services needed to sup-\nport these applications. We can then, in turn, examine the various ways in which\nsuch services might be implemented by a network architecture. Covering applica-\ntions early thus provides motivation for the remainder of the text.\nThe second half of the book—Chapters 6through 9—zooms in on four enor-\nmously important (and somewhat independent) topics in modern computer network-\ning. In Chapter 6, we examine wireless and mobile networks, including wireless\nLANs (including WiFi and Bluetooth), Cellular telephony networks (including\nGSM, 3G, and 4G), and mobility (in both IP and GSM networks). In Chapter 7\n(Multimedia Networking) we examine audio and video applications such as Internet\nphone, video conferencing, and streaming of stored media. We also look at how a\npacket-switched network can be designed to provide consistent quality of service to\naudio and video applications. In Chapter 8(Security in Computer Networks), we\nfirst look at the underpinnings of encryption and network security, and then we\nexamine how the basic theory is being applied in a broad range of Internet contexts.\nThe last chapter (Network Management) examines the key issues in network man-\nHomework Problems and Questions\n"
  },
  {
    "title": "Chapter 1 Review Questions",
    "content": "SECTION 1.1\nR1. What is the difference between a host and an end system? List several different\ntypes of end systems. Is a Web server an end system?\nR2. The word protocol is often used to describe diplomatic relations. How does\nWikipedia describe diplomatic protocol?\nR3. Why are standards important for protocols?\nSECTION 1.2\nR4. List six access technologies. Classify each one as home access, enterprise\naccess, or wide-area wireless access.\nR5. Is HFC transmission rate dedicated or shared among users? Are collisions\npossible in a downstream HFC channel? Why or why not?\nR6. List the available residential access technologies in your city. For each type\nof access, provide the advertised downstream rate, upstream rate, and\nmonthly price.\nR7. What is the transmission rate of Ethernet LANs?\nR8. What are some of the physical media that Ethernet can run over?\nR9. Dial-up modems, HFC, DSLand FTTH are all used for residential access.\nFor each of these access technologies, provide a range of transmission rates\nand comment on whether the transmission rate is shared or dedicated.\nR10. Describe the most popular wireless Internet access technologies today. Com-\npare and contrast them.\nSECTION 1.3\nR11. Suppose there is exactly one packet switch between a sending host and a\nreceiving host. The transmission rates between the sending host and the\nswitch and between the switch and the receiving host are R\nand R\n, respec-\ntively. Assuming that the switch uses store-and-forward packet switching,\nwhat is the total end-to-end delay to send a packet of length L ? (Ignore\nqueuing, propagation delay, and processing delay.)\nR12. What advantage does a circuit-switched network have over a packet-switched\nnetwork? What advantages does TDM have over FDM in a circuit-switched\nnetwork?\nR13. Suppose users share a 2 Mbps link. Also suppose each user transmits continu-\nously at 1 Mbps when transmitting, but each user transmits only 20 percent of\na. When circuit switching is used, how many users can be supported?\nb. For the remainder of this problem, suppose packet switching is used. Why\nwill there be essentially no queuing delay before the link if two or fewer\nusers transmit at the same time? Why will there be a queuing delay if\nthree users transmit at the same time?\nc. Find the probability that a given user is transmitting.\nd. Suppose now there are three users. Find the probability that at any given\ntime, all three users are transmitting simultaneously. Find the fraction of\ntime during which the queue grows.\nR14. Why will two ISPs at the same level of the hierarchy often peer with each\nother? How does an IXPearn money?\nR15. Some content providers have created their own networks. Describe Google’s\nnetwork. What motivates content providers to create these networks?\nSECTION 1.4\nR16. Consider sending a packet from a source host to a destination host over a\nfixed route. List the delay components in the end-to-end delay. Which of\nthese delays are constant and which are variable?\nR17. Visit the Transmission Versus Propagation Delay applet at the companion\nWeb site. Among the rates, propagation delay, and packet sizes available,\nfind a combination for which the sender finishes transmitting before the first\nbit of the packet reaches the receiver. Find another combination for which\nthe first bit of the packet reaches the receiver before the sender finishes\ntransmitting.\nR18. How long does it take a packet of length 1,000 bytes to propagate over a link\nof distance 2,500 km, propagation speed 2.5 · 10 8 m/s, and transmission rate\n2 Mbps? More generally, how long does it take a packet of length L to propa-\ngate over a link of distance d , propagation speed s , and transmission rate R\nbps? Does this delay depend on packet length? Does this delay depend on\ntransmission rate?\nR19. Suppose Host Awants to send a large file to Host B. The path from Host Ato\nHost B has three links, of rates R\n= 500 kbps, R\n= 2 Mbps, and R\n= 1 Mbps.\na. Assuming no other traffic in the network, what is the throughput for the\nfile transfer?\nb. Suppose the file is 4 million bytes. Dividing the file size by the throughput,\nroughly how long will it take to transfer the file to Host B?\nc. Repeat (a) and (b), but now with R\nreduced to 100 kbps.\nR20. Suppose end system Awants to send a large file to end system B. At a very\none of these packets arrives to a packet switch, what information in the\npacket does the switch use to determine the link onto which the packet is\nforwarded? Why is packet switching in the Internet analogous to driving from\none city to another and asking directions along the way?\nR21. Visit the Queuing and Loss applet at the companion Web site. What is the\nmaximum emission rate and the minimum transmission rate? With those\nrates, what is the traffic intensity? Run the applet with these rates and deter-\nmine how long it takes for packet loss to occur. Then repeat the experiment a\nsecond time and determine again how long it takes for packet loss to occur.\nAre the values different? Why or why not?\nSECTION 1.5\nR22. List five tasks that a layer can perform. Is it possible that one (or more) of\nthese tasks could be performed by two (or more) layers?\nR23. What are the five layers in the Internet protocol stack? What are the principal\nresponsibilities of each of these layers?\nR24. What is an application-layer message? Atransport-layer segment? Anetwork-\nlayer datagram? Alink-layer frame?\nR25. Which layers in the Internet protocol stack does a router process? Which\nlayers does a link-layer switch process? Which layers does a host process?\nSECTION 1.6\nR26. What is the difference between a virus and a worm?\nR27. Describe how a botnet can be created, and how it can be used for a DDoS\nattack.\nR28. Suppose Alice and Bob are sending packets to each other over a computer\nnetwork. Suppose Trudy positions herself in the network so that she can\ncapture all the packets sent by Alice and send whatever she wants to Bob;\nshe can also capture all the packets sent by Bob and send whatever she\nwants to Alice. List some of the malicious things Trudy can do from this\nposition.\nProblems\nP1. Design and describe an application-level protocol to be used between an\nautomatic teller machine and a bank’s centralized computer. Your protocol\nshould allow a user’s card and password to be verified, the account balance\n(which is maintained at the centralized computer) to be queried, and an\naccount withdrawal to be made (that is, money disbursed to the user). Your\nprotocol entities should be able to handle the all-too-common case in which\nthere is not enough money in the account to cover the withdrawal. Specify\nyour protocol by listing the messages exchanged and the action taken by the\nautomatic teller machine or the bank’s centralized computer on transmission\nand receipt of messages. Sketch the operation of your protocol for the case of a\nsimple withdrawal with no errors, using a diagram similar to that in Figure 1.2.\nExplicitly state the assumptions made by your protocol about the underlying\nend-to-end transport service.\nP2. Equation 1.1 gives a formula for the end-to-end delay of sending one packet\nof length L over N links of transmission rate R . Generalize this formula for\nsending P such packets back-to-back over the N links.\nP3. Consider an application that transmits data at a steady rate (for example, the\nsender generates an N -bit unit of data every k time units, where k is small and\nfixed). Also, when such an application starts, it will continue running for a\nrelatively long period of time. Answer the following questions, briefly justi-\nfying your answer:\na. Would a packet-switched network or a circuit-switched network be more\nappropriate for this application? Why?\nb. Suppose that a packet-switched network is used and the only traffic in\nthis network comes from such applications as described above. Further-\nmore, assume that the sum of the application data rates is less than the\ncapacities of each and every link. Is some form of congestion control\nneeded? Why?\nP4. Consider the circuit-switched network in Figure 1.13. Recall that there are 4\ncircuits on each link. Label the four switches A, B, C and D, going in the\nclockwise direction.\na. What is the maximum number of simultaneous connections that can be in\nprogress at any one time in this network?\nb. Suppose that all connections are between switches Aand C. What is the\nmaximum number of simultaneous connections that can be in progress?\nc. Suppose we want to make four connections between switches Aand C,\nand another four connections between switches B and D. Can we route\nthese calls through the four links to accommodate all eight connections?\nP5. Review the car-caravan analogy in Section 1.4. Assume a propagation speed\nof 100 km/hour.\na. Suppose the caravan travels 150 km, beginning in front of one tollbooth,\npassing through a second tollbooth, and finishing just after a third toll-\nbooth. What is the end-to-end delay?\nb. Repeat (a), now assuming that there are eight cars in the caravan instead\nof ten.\nP6. This elementary problem begins to explore propagation delay and transmis-\nsion delay, two central concepts in data networking. Consider two hosts, A\nand B, connected by a single link of rate R bps. Suppose that the two hosts\nare separated by m meters, and suppose the propagation speed along the link\nis s meters/sec. Host Ais to send a packet of size L bits to Host B.\na. Express the propagation delay, d\nprop\n, in terms of m and s .\nb. Determine the transmission time of the packet, d\ntrans\n, in terms of L\nand R .\nc. Ignoring processing and queuing delays, obtain an expression for the end-\nto-end delay.\nd. Suppose Host Abegins to transmit the packet at time t = 0. At time t = d\ntrans\n,\nwhere is the last bit of the packet?\ne. Suppose d\nprop\nis greater than d\ntrans\n. At time t = d\ntrans\n, where is the first bit of\nthe packet?\nf. Suppose d\nprop\nis less than d\ntrans\n. At time t = d\ntrans\n, where is the first bit of\nthe packet?\ng. Suppose s = 2.5 · 10 8 , L = 120 bits, and R = 56 kbps. Find the distance m\nso that d\nprop\nequals d\ntrans\n.\nP7. In this problem, we consider sending real-time voice from Host Ato Host B\nover a packet-switched network (VoIP). Host Aconverts analog voice to a\ndigital 64 kbps bit stream on the fly. Host Athen groups the bits into 56-byte\npackets. There is one link between Hosts Aand B; its transmission rate is 2\nMbps and its propagation delay is 10 msec. As soon as Host Agathers a\npacket, it sends it to Host B. As soon as Host B receives an entire packet, it\nconverts the packet’s bits to an analog signal. How much time elapses from\nthe time a bit is created (from the original analog signal at Host A) until the\nbit is decoded (as part of the analog signal at Host B)?\nP8. Suppose users share a 3 Mbps link. Also suppose each user requires\n150 kbps when transmitting, but each user transmits only 10 percent of the\ntime. (See the discussion of packet switching versus circuit switching in\nSection 1.3.)\na. When circuit switching is used, how many users can be supported?\nb. For the remainder of this problem, suppose packet switching is used. Find\nthe probability that a given user is transmitting.\nc. Suppose there are 120 users. Find the probability that at any given time,\nexactly n users are transmitting simultaneously. ( Hint : Use the binomial\ndistribution.)\nd. Find the probability that there are 21 or more users transmitting\nsimultaneously.\nVideoNote\nExploring propagation\ndelay and transmission\ndelay\nP9. Consider the discussion in Section 1.3 of packet switching versus circuit\nswitching in which an example is provided with a 1 Mbps link. Users are\ngenerating data at a rate of 100 kbps when busy, but are busy generating\ndata only with probability p = 0.1. Suppose that the 1 Mbps link is replaced\nby a 1 Gbps link.\na. What is N, the maximum number of users that can be supported\nsimultaneously under circuit switching?\nb. Now consider packet switching and a user population of M users. Give a\nformula (in terms of p , M , N ) for the probability that more than N users are\nsending data.\nP10. Consider a packet of length L which begins at end system Aand travels over\nthree links to a destination end system. These three links are connected by\ntwo packet switches. Let d\ni\n, s\ni\n, and R\ni\ndenote the length, propagation speed,\nand the transmission rate of link i, for i = 1, 2, 3. The packet switch delays\neach packet by d\nproc\n. Assuming no queuing delays, in terms of d\ni\n, s\ni\n, R\ni\n,\n( i = 1,2,3), and L, what is the total end-to-end delay for the packet? Suppose\nnow the packet is 1,500 bytes, the propagation speed on all three links is 2.5 ·\n10 8 m/s, the transmission rates of all three links are 2 Mbps, the packet switch\nprocessing delay is 3 msec, the length of the first link is 5,000 km, the length\nof the second link is 4,000 km, and the length of the last link is 1,000 km. For\nthese values, what is the end-to-end delay?\nP11. In the above problem, suppose R\n= R\n= R\n= R and d\nproc\n= 0. Further sup-\npose the packet switch does not store-and-forward packets but instead imme-\ndiately transmits each bit it receives before waiting for the entire packet to\narrive. What is the end-to-end delay?\nP12. Apacket switch receives a packet and determines the outbound link to which\nthe packet should be forwarded. When the packet arrives, one other packet is\nhalfway done being transmitted on this outbound link and four other packets\nare waiting to be transmitted. Packets are transmitted in order of arrival.\nSuppose all packets are 1,500 bytes and the link rate is 2 Mbps. What is the\nqueuing delay for the packet? More generally, what is the queuing delay\nwhen all packets have length L , the transmission rate is R , x bits of the\ncurrently-being-transmitted packet have been transmitted, and n packets are\nalready in the queue?\nP13. (a)Suppose N packets arrive simultaneously to a link at which no packets\nare currently being transmitted or queued. Each packet is of length L\nand the link has transmission rate R . What is the average queuing delay\nfor the N packets?\n(b)Now suppose that N such packets arrive to the link every LN/R seconds.\nWhat is the average queuing delay of a packet?\nP14. Consider the queuing delay in a router buffer. Let I denote traffic intensity;\nthat is, I = La/R . Suppose that the queuing delay takes the form IL/R (1 – I )\nfor I < 1.\na. Provide a formula for the total delay, that is, the queuing delay plus the\ntransmission delay.\nb. Plot the total delay as a function of L/R .\nP15. Let a denote the rate of packets arriving at a link in packets/sec, and let μ\ndenote the link’s transmission rate in packets/sec. Based on the formula for\nthe total delay (i.e., the queuing delay plus the transmission delay) derived in\nthe previous problem, derive a formula for the total delay in terms of a and μ .\nP16. Consider a router buffer preceding an outbound link. In this problem, you will\nuse Little’s formula, a famous formula from queuing theory. Let N denote the\naverage number of packets in the buffer plus the packet being transmitted. Let\na denote the rate of packets arriving at the link. Let d denote the average total\ndelay (i.e., the queuing delay plus the transmission delay) experienced by a\npacket. Little’s formula is N = a · d . Suppose that on average, the buffer con-\ntains 10 packets, and the average packet queuing delay is 10 msec. The link’s\ntransmission rate is 100 packets/sec. Using Little’s formula, what is the aver-\nage packet arrival rate, assuming there is no packet loss?\nP17. a. Generalize Equation 1.2 in Section 1.4.3 for heterogeneous processing\nrates, transmission rates, and propagation delays.\nb. Repeat (a), but now also suppose that there is an average queuing delay of\nd\nqueue\nat each node.\nP18. Perform a Traceroute between source and destination on the same continent\nat three different hours of the day.\na. Find the average and standard deviation of the round-trip delays at each of\nthe three hours.\nb. Find the number of routers in the path at each of the three hours. Did the\npaths change during any of the hours?\nc. Try to identify the number of ISPnetworks that the Traceroute packets pass\nthrough from source to destination. Routers with similar names and/or similar\nIPaddresses should be considered as part of the same ISP. In your experiments,\ndo the largest delays occur at the peering interfaces between adjacent ISPs?\nd. Repeat the above for a source and destination on different continents.\nCompare the intra-continent and inter-continent results.\nP19. (a) Visit the site www.traceroute.org and perform traceroutes from two different\ncities in France to the same destination host in the United States. How many\nlinks are the same in the two traceroutes? Is the transatlantic link the same?\nVideoNote\nUsing Traceroute to\ndiscover network\npaths and measure\nnetwork delay\n(b) Repeat (a) but this time choose one city in France and another city in\nGermany.\n(c) Pick a city in the United States, and perform traceroutes to two hosts, each\nin a different city in China. How many links are common in the two\ntraceroutes? Do the two traceroutes diverge before reaching China?\nP20. Consider the throughput example corresponding to Figure 1.20(b). Now\nsuppose that there are M client-server pairs rather than 10. Denote R\ns\n, R\nc\n, and\nR for the rates of the server links, client links, and network link. Assume all\nother links have abundant capacity and that there is no other traffic in the\nnetwork besides the traffic generated by the M client-server pairs. Derive a\ngeneral expression for throughput in terms of R\ns\n, R\nc\n, R , and M .\nP21. Consider Figure 1.19(b). Now suppose that there are M paths between the\nserver and the client. No two paths share any link. Path k ( k = 1, . . ., M ) con-\nsists of N links with transmission rates R k\n, R k\n, . . ., R k\nN\n. If the server can only\nuse one path to send data to the client, what is the maximum throughput that\nthe server can achieve? If the server can use all M paths to send data, what is\nthe maximum throughput that the server can achieve?\nP22. Consider Figure 1.19(b). Suppose that each link between the server and the\nclient has a packet loss probability p, and the packet loss probabilities for\nthese links are independent. What is the probability that a packet (sent by the\nserver) is successfully received by the receiver? If a packet is lost in the path\nfrom the server to the client, then the server will re-transmit the packet. On\naverage, how many times will the server re-transmit the packet in order for\nthe client to successfully receive the packet?\nP23. Consider Figure 1.19(a). Assume that we know the bottleneck link along the\npath from the server to the client is the first link with rate R\ns\nbits/sec. Suppose\nwe send a pair of packets back to back from the server to the client, and there\nis no other traffic on this path. Assume each packet of size L bits, and both\nlinks have the same propagation delay d\nprop\n.\na. What is the packet inter-arrival time at the destination? That is, how much\ntime elapses from when the last bit of the first packet arrives until the last\nbit of the second packet arrives?\nb. Now assume that the second link is the bottleneck link (i.e., R\nc\n< R\ns\n). Is it\npossible that the second packet queues at the input queue of the second\nlink? Explain. Now suppose that the server sends the second packet T sec-\nonds after sending the first packet. How large must T be to ensure no\nqueuing before the second link? Explain.\nP24. Suppose you would like to urgently deliver 40 terabytes data from Boston to\nLos Angeles. You have available a 100 Mbps dedicated link for data transfer.\nWould you prefer to transmit the data via this link or instead use FedEx over-\nP25. Suppose two hosts, Aand B, are separated by 20,000 kilometers and are\nconnected by a direct link of R = 2 Mbps. Suppose the propagation speed\nover the link is 2.5  10 8 meters/sec.\na. Calculate the bandwidth-delay product, R  d\nprop\n.\nb. Consider sending a file of 800,000 bits from Host Ato Host B. Suppose\nthe file is sent continuously as one large message. What is the maximum\nnumber of bits that will be in the link at any given time?\nc. Provide an interpretation of the bandwidth-delay product.\nd. What is the width (in meters) of a bit in the link? Is it longer than a foot-\nball field?\ne. Derive a general expression for the width of a bit in terms of the propaga-\ntion speed s, the transmission rate R, and the length of the link m .\nP26. Referring to problem P25, suppose we can modify R . For what value of R is\nthe width of a bit as long as the length of the link?\nP27. Consider problem P25 but now with a link of R = 1 Gbps.\na. Calculate the bandwidth-delay product, R  d\nprop\n.\nb. Consider sending a file of 800,000 bits from Host Ato Host B. Suppose\nthe file is sent continuously as one big message. What is the maximum\nnumber of bits that will be in the link at any given time?\nc. What is the width (in meters) of a bit in the link?\nP28. Refer again to problem P25.\na. How long does it take to send the file, assuming it is sent continuously?\nb. Suppose now the file is broken up into 20 packets with each packet con-\ntaining 40,000 bits. Suppose that each packet is acknowledged by the\nreceiver and the transmission time of an acknowledgment packet is\nnegligible. Finally, assume that the sender cannot send a packet until the\npreceding one is acknowledged. How long does it take to send the file?\nc. Compare the results from (a) and (b).\nP29. Suppose there is a 10 Mbps microwave link between a geostationary satellite\nand its base station on Earth. Every minute the satellite takes a digital photo and\nsends it to the base station. Assume a propagation speed of 2.4  10 8 meters/sec.\na. What is the propagation delay of the link?\nb. What is the bandwidth-delay product, R · d\nprop\n?\nc. Let x denote the size of the photo. What is the minimum value of x for the\nmicrowave link to be continuously transmitting?\nP30. Consider the airline travel analogy in our discussion of layering in Section\n1.5, and the addition of headers to protocol data units as they flow down\nthe protocol stack. Is there an equivalent notion of header information that\nis added to passengers and baggage as they move down the airline protocol\nstack?\nP31. In modern packet-switched networks, including the Internet, the source host\nsegments long, application-layer messages (for example, an image or a music\nfile) into smaller packets and sends the packets into the network. The receiver\nthen reassembles the packets back into the original message. We refer to this\nprocess as messagesegmentation . Figure 1.27illustrates the end-to-end\ntransport of a message with and without message segmentation. Consider a\nmessage that is 8 · 10 6 bits long that is to be sent from source to destination in\nqueuing, and processing delays.\na. Consider sending the message from source to destination without message\nsegmentation. How long does it take to move the message from the source\nhost to the first packet switch? Keeping in mind that each switch uses\nstore-and-forward packet switching, what is the total time to move the\nmessage from source host to destination host?\nb. Now suppose that the message is segmented into 800 packets, with each\npacket being 10,000 bits long. How long does it take to move the first\npacket from source host to the first switch? When the first packet is being\nsent from the first switch to the second switch, the second packet is being\nsent from the source host to the first switch. At what time will the second\npacket be fully received at the first switch?\nc. How long does it take to move the file from source host to destination host\nwhen message segmentation is used? Compare this result with your\nanswer in part (a) and comment.\na. Source Packet switch Packet switch Destination\nMessage\nb. Source Packet switch\nPacket\nPacket switch Destination\nsegmentation; (b) with message segmentation\nd. In addition to reducing delay, what are reasons to use message segmentation?\ne. Discuss the drawbacks of message segmentation.\nP32. Experiment with the Message Segmentation applet at the book’s Web site. Do\nthe delays in the applet correspond to the delays in the previous problem?\nHow do link propagation delays affect the overall end-to-end delay for packet\nswitching (with message segmentation) and for message switching?\nP33. Consider sending a large file of F bits from Host Ato Host B. There are three\nlinks (and two switches) between Aand B, and the links are uncongested (that\nis, no queuing delays). Host Asegments the file into segments of S bits each and\nadds 80 bits of header to each segment, forming packets of L = 80 + S bits. Each\nlink has a transmission rate of R bps. Find the value of S that minimizes the\ndelay of moving the file from Host Ato Host B. Disregard propagation delay.\nP34. Skype offers a service that allows you to make a phone call from a PC to an\nordinary phone. This means that the voice call must pass through both the\nInternet and through a telephone network. Discuss how this might be done.\nWireshark Lab\n“Tell me and I forget. Show me and I remember. Involve me and I understand.”\nChinese proverb\nOne’s understanding of network protocols can often be greatly deepened by seeing\nthem in action and by playing around with them—observing the sequence of mes-\nsages exchanged between two protocol entities, delving into the details of protocol\noperation, causing protocols to perform certain actions, and observing these actions\nand their consequences. This can be done in simulated scenarios or in a real network\nenvironment such as the Internet. The Java applets at the textbook Web site take the\nfirst approach. In the Wireshark labs, we’ll take the latter approach. You’ll run net-\nwork applications in various scenarios using a computer on your desk, at home, or\nin a lab. You’ll observe the network protocols in your computer, interacting and\nexchanging messages with protocol entities executing elsewhere in the Internet.\nThus, you and your computer will be an integral part of these live labs. You’ll\nobserve—and you’ll learn—by doing.\nThe basic tool for observing the messages exchanged between executing\nprotocol entities is called a packet sniffer . As the name suggests, a packet sniffer\npassively copies (sniffs) messages being sent from and received by your computer;\nit also displays the contents of the various protocol fields of these captured mes-\nsages. Ascreenshot of the Wireshark packet sniffer is shown in Figure 1.28. Wire-\nshark is a free packet sniffer that runs on Windows, Linux/Unix, and Mac\nCommand\nmenus\nListing of\ncaptured\npackets\nDetails of\nselected\npacket\nheader\nPacket\ncontents in\nhexadecimal\nand ASCII\nby permission of the Wireshark Foundation.)\ncomputers. Throughout the textbook, you will find Wireshark labs that allow you to\nexplore a number of the protocols studied in the chapter. In this first Wireshark lab,\nyou’ll obtain and install a copy of Wireshark, access a Web site, and capture and\nexamine the protocol messages being exchanged between your Web browser and the\nWeb server.\nYou can find full details about this first Wireshark lab (including instructions\nabout how to obtain and install Wireshark) at the Web site http://www.awl.com/\nkurose-ross.\n"
  }
]